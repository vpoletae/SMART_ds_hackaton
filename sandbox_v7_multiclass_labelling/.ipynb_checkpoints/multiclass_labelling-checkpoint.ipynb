{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned featured file from v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_df = pd.read_csv('all_topics.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goal_first_step', 'default_goal_type', 'is_questioned',\n",
       "       'are_first_steps_known', 'is_time_certain', 'is_certainly_imagined',\n",
       "       'are_obstackles_expected', 'goal_domain_key_pos', 'goal_name_key_pos',\n",
       "       'goal_weight', 'goal_words', 'goal_verbs_counter', 'goal_nouns_counter',\n",
       "       'goal_numr_counter', 'goal_adj_counter', 'goal_digit_counter',\n",
       "       'goal_aver_word_len', 'label_attractor_knowledge',\n",
       "       'label_attractor_hard_skill', 'label_attractor_soft_skill',\n",
       "       'label_attractor_tool', 'label_attractor_community',\n",
       "       'label_attractor_subjectivity', 'label_attractor_habits',\n",
       "       'label_attractor_career', 'label_attractor_fixing',\n",
       "       'label_attractor_art', 'label_attractor_health'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_cnn = all_topics_df[['goal_name_key_pos', 'label_attractor_knowledge',\n",
    "       'label_attractor_hard_skill', 'label_attractor_soft_skill',\n",
    "       'label_attractor_tool', 'label_attractor_community',\n",
    "       'label_attractor_subjectivity', 'label_attractor_habits',\n",
    "       'label_attractor_career', 'label_attractor_fixing',\n",
    "       'label_attractor_art', 'label_attractor_health']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "topics_cnn.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = topics_cnn['goal_name_key_pos']\n",
    "y = topics_cnn.drop(columns = ['goal_name_key_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer()\n",
    "# X = tfidf.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4619"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(token.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = token.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = int()\n",
    "for i in encoded_text:\n",
    "    len_ = len(i)\n",
    "    if len_ > max_len:\n",
    "        max_len = len_\n",
    "        \n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(encoded_text, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 1., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vec_size, input_length=max_len))\n",
    "\n",
    "model.add(Conv1D(32, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 127, 100)          461900    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 126, 32)           6432      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 63, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 63, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 63, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 63, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 63, 16)            528       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 11)                187       \n",
      "=================================================================\n",
      "Total params: 470,103\n",
      "Trainable params: 470,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test= np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13562 samples, validate on 3391 samples\n",
      "Epoch 1/10\n",
      "   32/13562 [..............................] - ETA: 32sWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must be broadcastable: logits_size=[32,11] labels_size=[352,11]\n\t [[node loss/dense_17_loss/softmax_cross_entropy_with_logits (defined at c:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_distributed_function_7046]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-6779aac37ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  logits and labels must be broadcastable: logits_size=[32,11] labels_size=[352,11]\n\t [[node loss/dense_17_loss/softmax_cross_entropy_with_logits (defined at c:\\users\\vpoletae\\appdata\\local\\continuum\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_distributed_function_7046]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_text_vectors = topics[['goal_name_key_pos', 'goal_domain_key_pos', 'label_attractor_art']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectors approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vpoletae\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "topics_text_vectors.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goal_name_key_pos', 'goal_domain_key_pos', 'label_attractor_art'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_text_vectors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vpoletae\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\vpoletae\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "topics_text_vectors['space'] = ' '\n",
    "topics_text_vectors['name_domain'] = topics_text_vectors['goal_name_key_pos'] + topics_text_vectors['space'] + topics_text_vectors['goal_domain_key_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = topics_text_vectors['name_domain']\n",
    "y = topics_text_vectors['label_attractor_art']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        отстать поезд современность творчество создани...\n",
       "1        самореализация универсальный компетенция гибки...\n",
       "2        образ жизнь иностранный язык гуманитарный знан...\n",
       "3        обновление устаревший информация прикладной зн...\n",
       "4        повышение результативность труд универсальный ...\n",
       "                               ...                        \n",
       "18013    приобретение новый знание навык успешный обуче...\n",
       "18014                   быть нужный работодатель математик\n",
       "18016    сохранить здоровье спорт зож внешность самочув...\n",
       "18018    зарабатывать деньга прикладной знание навык ру...\n",
       "18019                   получение навык естественный наука\n",
       "Name: name_domain, Length: 16920, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16920, 5062)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13536x5062 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 111245 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_v_xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_v_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = art_v_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      3079\n",
      "           1       0.33      0.01      0.01       305\n",
      "\n",
      "    accuracy                           0.91      3384\n",
      "   macro avg       0.62      0.50      0.48      3384\n",
      "weighted avg       0.86      0.91      0.87      3384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9092789598108747"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012861736334405146"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5026291269786337"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/topic_art_vect_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(art_v_xgb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural net approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = topics_text_vectors['name_domain']\n",
    "y = topics_text_vectors['label_attractor_art']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5082"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(token.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = token.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = int()\n",
    "for i in encoded_text:\n",
    "    len_ = len(i)\n",
    "    if len_ > max_len:\n",
    "        max_len = len_\n",
    "        \n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 131\n",
    "X = pad_sequences(encoded_text, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16920, 131)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vec_size, input_length=max_length))\n",
    "\n",
    "model.add(Conv1D(32, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test= np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13536 samples, validate on 3384 samples\n",
      "Epoch 1/600\n",
      "13536/13536 [==============================] - 10s 741us/sample - loss: 0.3180 - accuracy: 0.9084 - val_loss: 0.4432 - val_accuracy: 0.9099\n",
      "Epoch 2/600\n",
      "13536/13536 [==============================] - 9s 684us/sample - loss: 0.3078 - accuracy: 0.9098 - val_loss: 0.4001 - val_accuracy: 0.9099\n",
      "Epoch 3/600\n",
      "13536/13536 [==============================] - 9s 676us/sample - loss: 0.3066 - accuracy: 0.9098 - val_loss: 0.4098 - val_accuracy: 0.9099\n",
      "Epoch 4/600\n",
      "13536/13536 [==============================] - 9s 679us/sample - loss: 0.3047 - accuracy: 0.9098 - val_loss: 0.3972 - val_accuracy: 0.9099\n",
      "Epoch 5/600\n",
      "13536/13536 [==============================] - 9s 674us/sample - loss: 0.3025 - accuracy: 0.9098 - val_loss: 0.4129 - val_accuracy: 0.9099\n",
      "Epoch 6/600\n",
      "13536/13536 [==============================] - 9s 675us/sample - loss: 0.3014 - accuracy: 0.9098 - val_loss: 0.3679 - val_accuracy: 0.9099041 - \n",
      "Epoch 7/600\n",
      "13536/13536 [==============================] - 9s 675us/sample - loss: 0.2992 - accuracy: 0.9098 - val_loss: 0.3750 - val_accuracy: 0.9099\n",
      "Epoch 8/600\n",
      "13536/13536 [==============================] - 9s 678us/sample - loss: 0.2926 - accuracy: 0.9098 - val_loss: 0.3873 - val_accuracy: 0.9099\n",
      "Epoch 9/600\n",
      "13536/13536 [==============================] - 9s 674us/sample - loss: 0.2884 - accuracy: 0.9098 - val_loss: 0.3718 - val_accuracy: 0.9099\n",
      "Epoch 10/600\n",
      "13536/13536 [==============================] - 9s 682us/sample - loss: 0.2823 - accuracy: 0.9098 - val_loss: 0.3771 - val_accuracy: 0.9099\n",
      "Epoch 11/600\n",
      "13536/13536 [==============================] - 9s 694us/sample - loss: 0.2775 - accuracy: 0.9098 - val_loss: 0.3811 - val_accuracy: 0.9099\n",
      "Epoch 12/600\n",
      "13536/13536 [==============================] - 9s 692us/sample - loss: 0.2703 - accuracy: 0.9098 - val_loss: 0.3981 - val_accuracy: 0.9099\n",
      "Epoch 13/600\n",
      "13536/13536 [==============================] - 9s 697us/sample - loss: 0.2643 - accuracy: 0.9098 - val_loss: 0.4034 - val_accuracy: 0.9099\n",
      "Epoch 14/600\n",
      "13536/13536 [==============================] - 9s 701us/sample - loss: 0.2613 - accuracy: 0.9098 - val_loss: 0.4136 - val_accuracy: 0.9099\n",
      "Epoch 15/600\n",
      "13536/13536 [==============================] - 10s 702us/sample - loss: 0.2557 - accuracy: 0.9098 - val_loss: 0.4494 - val_accuracy: 0.9099\n",
      "Epoch 16/600\n",
      "13536/13536 [==============================] - 9s 697us/sample - loss: 0.2517 - accuracy: 0.9098 - val_loss: 0.4540 - val_accuracy: 0.9099\n",
      "Epoch 17/600\n",
      "13536/13536 [==============================] - 9s 700us/sample - loss: 0.2461 - accuracy: 0.9098 - val_loss: 0.4710 - val_accuracy: 0.9099462 - accuracy: 0.90\n",
      "Epoch 18/600\n",
      "13536/13536 [==============================] - 9s 690us/sample - loss: 0.2401 - accuracy: 0.9096 - val_loss: 0.4922 - val_accuracy: 0.9099\n",
      "Epoch 19/600\n",
      "13536/13536 [==============================] - 9s 689us/sample - loss: 0.2324 - accuracy: 0.9116 - val_loss: 0.5144 - val_accuracy: 0.9031\n",
      "Epoch 20/600\n",
      "13536/13536 [==============================] - 9s 692us/sample - loss: 0.2233 - accuracy: 0.9159 - val_loss: 0.5303 - val_accuracy: 0.8986\n",
      "Epoch 21/600\n",
      "13536/13536 [==============================] - 10s 715us/sample - loss: 0.2143 - accuracy: 0.9209 - val_loss: 0.5802 - val_accuracy: 0.8972\n",
      "Epoch 22/600\n",
      "13536/13536 [==============================] - 10s 717us/sample - loss: 0.2031 - accuracy: 0.9271 - val_loss: 0.5820 - val_accuracy: 0.8951\n",
      "Epoch 23/600\n",
      "13536/13536 [==============================] - 10s 722us/sample - loss: 0.1947 - accuracy: 0.9297 - val_loss: 0.6084 - val_accuracy: 0.8771\n",
      "Epoch 24/600\n",
      "13536/13536 [==============================] - 10s 705us/sample - loss: 0.1933 - accuracy: 0.9301 - val_loss: 0.6802 - val_accuracy: 0.8865\n",
      "Epoch 25/600\n",
      "13536/13536 [==============================] - 10s 710us/sample - loss: 0.1789 - accuracy: 0.9365 - val_loss: 0.8179 - val_accuracy: 0.8839\n",
      "Epoch 26/600\n",
      "13536/13536 [==============================] - 9s 690us/sample - loss: 0.1795 - accuracy: 0.9376 - val_loss: 0.7421 - val_accuracy: 0.8821\n",
      "Epoch 27/600\n",
      "13536/13536 [==============================] - 9s 684us/sample - loss: 0.1760 - accuracy: 0.9391 - val_loss: 0.7718 - val_accuracy: 0.8797\n",
      "Epoch 28/600\n",
      "13536/13536 [==============================] - 9s 696us/sample - loss: 0.1722 - accuracy: 0.9400 - val_loss: 0.8529 - val_accuracy: 0.8874\n",
      "Epoch 29/600\n",
      "13536/13536 [==============================] - 10s 703us/sample - loss: 0.1717 - accuracy: 0.9414 - val_loss: 0.7659 - val_accuracy: 0.8791\n",
      "Epoch 30/600\n",
      "13536/13536 [==============================] - 9s 699us/sample - loss: 0.1668 - accuracy: 0.9419 - val_loss: 0.8388 - val_accuracy: 0.8856\n",
      "Epoch 31/600\n",
      "13536/13536 [==============================] - 10s 717us/sample - loss: 0.1631 - accuracy: 0.9422 - val_loss: 0.9254 - val_accuracy: 0.8827\n",
      "Epoch 00031: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23d48a2ac08>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=600, validation_data=(X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23d4dde7588>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23d4e30c1c8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "[0.9253777685458496, 0.8826832]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(model.evaluate(X_test,y_test,verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3079\n",
      "           1       0.07      0.03      0.04       305\n",
      "\n",
      "    accuracy                           0.88      3384\n",
      "   macro avg       0.49      0.50      0.49      3384\n",
      "weighted avg       0.83      0.88      0.86      3384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8826832151300237"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038740920096852295"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49687571544944864"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/topic_art_vect_nn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
