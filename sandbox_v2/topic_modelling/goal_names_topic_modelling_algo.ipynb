{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = pd.read_csv('../joint_clean_data/topics.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal_id</th>\n",
       "      <th>goal_domain_original</th>\n",
       "      <th>goal_name_type_original</th>\n",
       "      <th>goal_domain_LoW</th>\n",
       "      <th>goal_name_type_LoW</th>\n",
       "      <th>goal_domain_no_noise</th>\n",
       "      <th>goal_name_type_no_noise</th>\n",
       "      <th>goal_domain_mean_pos</th>\n",
       "      <th>goal_name_type_mean_pos</th>\n",
       "      <th>remove</th>\n",
       "      <th>...</th>\n",
       "      <th>label_attractor_hard_skill</th>\n",
       "      <th>label_attractor_soft_skill</th>\n",
       "      <th>label_attractor_tool</th>\n",
       "      <th>label_attractor_community</th>\n",
       "      <th>label_attractor_subjectivity</th>\n",
       "      <th>label_attractor_habits</th>\n",
       "      <th>label_attractor_career</th>\n",
       "      <th>label_attractor_fixing</th>\n",
       "      <th>label_attractor_art</th>\n",
       "      <th>label_attractor_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>творчество и создание нового изобразительное и...</td>\n",
       "      <td>не отстать от поезда современности получить зн...</td>\n",
       "      <td>['творчество', 'и', 'создание', 'нового', 'изо...</td>\n",
       "      <td>['не', 'отстать', 'от', 'поезда', 'современнос...</td>\n",
       "      <td>творчество создание новое изобразительный иску...</td>\n",
       "      <td>отстать поезд современность получить знание но...</td>\n",
       "      <td>творчество создание новое изобразительный иску...</td>\n",
       "      <td>отстать поезд современность получить знание но...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>универсальные компетенции  гибкие навыки soft ...</td>\n",
       "      <td>самореализация получить знания в новой области...</td>\n",
       "      <td>['универсальные', 'компетенции', '', 'гибкие',...</td>\n",
       "      <td>['самореализация', 'получить', 'знания', 'в', ...</td>\n",
       "      <td>универсальный компетенция  гибкий навык soft s...</td>\n",
       "      <td>самореализация получить знание новый область  ...</td>\n",
       "      <td>универсальный компетенция гибкий навык навык о...</td>\n",
       "      <td>самореализация получить знание новый область п...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>иностранные языки  гуманитарные знания и навык...</td>\n",
       "      <td>улучшенный образ жизни включиться в новый прое...</td>\n",
       "      <td>['иностранные', 'языки', '', 'гуманитарные', '...</td>\n",
       "      <td>['улучшенный', 'образ', 'жизни', 'включиться',...</td>\n",
       "      <td>иностранный язык  гуманитарный знание навык ин...</td>\n",
       "      <td>улучшить образ жизнь включиться новый проект д...</td>\n",
       "      <td>иностранный язык гуманитарный знание навык ино...</td>\n",
       "      <td>образ жизнь включиться новый проект деятельность</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>прикладные знания и навыки  ручной труд информ...</td>\n",
       "      <td>обновление устаревшей информации развить имеющ...</td>\n",
       "      <td>['прикладные', 'знания', 'и', 'навыки', '', 'р...</td>\n",
       "      <td>['обновление', 'устаревшей', 'информации', 'ра...</td>\n",
       "      <td>прикладной знание навык  ручной труд информаци...</td>\n",
       "      <td>обновление устаревший информация развить иметь...</td>\n",
       "      <td>прикладной знание навык ручной труд информация...</td>\n",
       "      <td>обновление устаревший информация развить знани...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>универсальные компетенции  гибкие навыки soft ...</td>\n",
       "      <td>повышение результативности труда получить знан...</td>\n",
       "      <td>['универсальные', 'компетенции', '', 'гибкие',...</td>\n",
       "      <td>['повышение', 'результативности', 'труда', 'по...</td>\n",
       "      <td>универсальный компетенция  гибкий навык soft s...</td>\n",
       "      <td>повышение результативность труд получить знани...</td>\n",
       "      <td>универсальный компетенция гибкий навык планиро...</td>\n",
       "      <td>повышение результативность труд получить знани...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   goal_id                               goal_domain_original  \\\n",
       "0       19  творчество и создание нового изобразительное и...   \n",
       "1       20  универсальные компетенции  гибкие навыки soft ...   \n",
       "2       21  иностранные языки  гуманитарные знания и навык...   \n",
       "3       22  прикладные знания и навыки  ручной труд информ...   \n",
       "4       23  универсальные компетенции  гибкие навыки soft ...   \n",
       "\n",
       "                             goal_name_type_original  \\\n",
       "0  не отстать от поезда современности получить зн...   \n",
       "1  самореализация получить знания в новой области...   \n",
       "2  улучшенный образ жизни включиться в новый прое...   \n",
       "3  обновление устаревшей информации развить имеющ...   \n",
       "4  повышение результативности труда получить знан...   \n",
       "\n",
       "                                     goal_domain_LoW  \\\n",
       "0  ['творчество', 'и', 'создание', 'нового', 'изо...   \n",
       "1  ['универсальные', 'компетенции', '', 'гибкие',...   \n",
       "2  ['иностранные', 'языки', '', 'гуманитарные', '...   \n",
       "3  ['прикладные', 'знания', 'и', 'навыки', '', 'р...   \n",
       "4  ['универсальные', 'компетенции', '', 'гибкие',...   \n",
       "\n",
       "                                  goal_name_type_LoW  \\\n",
       "0  ['не', 'отстать', 'от', 'поезда', 'современнос...   \n",
       "1  ['самореализация', 'получить', 'знания', 'в', ...   \n",
       "2  ['улучшенный', 'образ', 'жизни', 'включиться',...   \n",
       "3  ['обновление', 'устаревшей', 'информации', 'ра...   \n",
       "4  ['повышение', 'результативности', 'труда', 'по...   \n",
       "\n",
       "                                goal_domain_no_noise  \\\n",
       "0  творчество создание новое изобразительный иску...   \n",
       "1  универсальный компетенция  гибкий навык soft s...   \n",
       "2  иностранный язык  гуманитарный знание навык ин...   \n",
       "3  прикладной знание навык  ручной труд информаци...   \n",
       "4  универсальный компетенция  гибкий навык soft s...   \n",
       "\n",
       "                             goal_name_type_no_noise  \\\n",
       "0  отстать поезд современность получить знание но...   \n",
       "1  самореализация получить знание новый область  ...   \n",
       "2  улучшить образ жизнь включиться новый проект д...   \n",
       "3  обновление устаревший информация развить иметь...   \n",
       "4  повышение результативность труд получить знани...   \n",
       "\n",
       "                                goal_domain_mean_pos  \\\n",
       "0  творчество создание новое изобразительный иску...   \n",
       "1  универсальный компетенция гибкий навык навык о...   \n",
       "2  иностранный язык гуманитарный знание навык ино...   \n",
       "3  прикладной знание навык ручной труд информация...   \n",
       "4  универсальный компетенция гибкий навык планиро...   \n",
       "\n",
       "                             goal_name_type_mean_pos  remove  ...  \\\n",
       "0  отстать поезд современность получить знание но...       0  ...   \n",
       "1  самореализация получить знание новый область п...       0  ...   \n",
       "2   образ жизнь включиться новый проект деятельность       0  ...   \n",
       "3  обновление устаревший информация развить знани...       0  ...   \n",
       "4  повышение результативность труд получить знани...       0  ...   \n",
       "\n",
       "   label_attractor_hard_skill  label_attractor_soft_skill  \\\n",
       "0                           1                           1   \n",
       "1                           1                           0   \n",
       "2                           1                           1   \n",
       "3                           1                           0   \n",
       "4                           1                           0   \n",
       "\n",
       "   label_attractor_tool  label_attractor_community  \\\n",
       "0                     0                          1   \n",
       "1                     1                          0   \n",
       "2                     0                          0   \n",
       "3                     0                          0   \n",
       "4                     0                          0   \n",
       "\n",
       "   label_attractor_subjectivity  label_attractor_habits  \\\n",
       "0                             0                       1   \n",
       "1                             1                       0   \n",
       "2                             0                       0   \n",
       "3                             1                       1   \n",
       "4                             0                       0   \n",
       "\n",
       "   label_attractor_career  label_attractor_fixing  label_attractor_art  \\\n",
       "0                       1                       1                    0   \n",
       "1                       1                       0                    1   \n",
       "2                       0                       1                    0   \n",
       "3                       1                       1                    1   \n",
       "4                       0                       0                    1   \n",
       "\n",
       "   label_attractor_health  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goal_id', 'goal_domain_original', 'goal_name_type_original',\n",
       "       'goal_domain_LoW', 'goal_name_type_LoW', 'goal_domain_no_noise',\n",
       "       'goal_name_type_no_noise', 'goal_domain_mean_pos',\n",
       "       'goal_name_type_mean_pos', 'remove', 'are_first_steps_known',\n",
       "       'is_time_certain', 'is_certainly_imagined', 'are_obstackles_expected',\n",
       "       'topic_words', 'goal_words', 'topic_letters', 'goal_letters',\n",
       "       'topic_aver_word_len', 'goal_aver_word_len', 'goal_verbs_counter',\n",
       "       'goal_nouns_counter', 'goal_numr_counter', 'goal_adj_counter',\n",
       "       'goal_digit_counter', 'goal_name', 'goal_name_LoW',\n",
       "       'goal_name_clean_LoW', 'goal_name_clean_NV_LoW',\n",
       "       'label_attractor_knowledge', 'label_attractor_hard_skill',\n",
       "       'label_attractor_soft_skill', 'label_attractor_tool',\n",
       "       'label_attractor_community', 'label_attractor_subjectivity',\n",
       "       'label_attractor_habits', 'label_attractor_career',\n",
       "       'label_attractor_fixing', 'label_attractor_art',\n",
       "       'label_attractor_health'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics[topics['remove'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.drop(columns=['remove'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_cols = ['label_attractor_knowledge',\n",
    "       'label_attractor_hard_skill', 'label_attractor_soft_skill',\n",
    "       'label_attractor_tool', 'label_attractor_community',\n",
    "       'label_attractor_subjectivity', 'label_attractor_habits',\n",
    "       'label_attractor_career', 'label_attractor_fixing',\n",
    "       'label_attractor_art', 'label_attractor_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in topic_cols:\n",
    "    topics_text_vectors = topics[['goal_name_clean_NV_LoW', topic]]\n",
    "    topics_text_vectors.dropna(inplace=True)\n",
    "    text = topics_text_vectors['goal_name_clean_NV_LoW']\n",
    "    y = topics_text_vectors[topic]\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X = tfidf.fit_transform(text)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    name = topic.split('_')[-1]\n",
    "    with open(f'../models/topics_goal_name/goal_{name}_vect_xgb.pkl', 'wb') as f:\n",
    "        pickle.dump(xgb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    vec_size = 100\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, vec_size, input_length=max_len))\n",
    "\n",
    "    model.add(Conv1D(32, 2, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 7s 458us/sample - loss: 0.3612 - accuracy: 0.8860 - val_loss: 0.4519 - val_accuracy: 0.8946\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 6s 408us/sample - loss: 0.3409 - accuracy: 0.8945 - val_loss: 0.4486 - val_accuracy: 0.8946\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 6s 423us/sample - loss: 0.3398 - accuracy: 0.8945 - val_loss: 0.4189 - val_accuracy: 0.8946\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 6s 436us/sample - loss: 0.3388 - accuracy: 0.8945 - val_loss: 0.4283 - val_accuracy: 0.8946\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 6s 417us/sample - loss: 0.3382 - accuracy: 0.8945 - val_loss: 0.4440 - val_accuracy: 0.8946\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 409us/sample - loss: 0.3378 - accuracy: 0.8945 - val_loss: 0.4308 - val_accuracy: 0.8946\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 5s 378us/sample - loss: 0.3357 - accuracy: 0.8945 - val_loss: 0.4251 - val_accuracy: 0.8946\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 6s 404us/sample - loss: 0.3321 - accuracy: 0.8939 - val_loss: 0.4315 - val_accuracy: 0.8946\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 6s 398us/sample - loss: 0.3250 - accuracy: 0.8948 - val_loss: 0.4131 - val_accuracy: 0.8898\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 6s 408us/sample - loss: 0.3153 - accuracy: 0.8969 - val_loss: 0.4077 - val_accuracy: 0.8870\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 6s 389us/sample - loss: 0.3060 - accuracy: 0.8988 - val_loss: 0.4197 - val_accuracy: 0.8809\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 5s 379us/sample - loss: 0.2919 - accuracy: 0.9031 - val_loss: 0.4078 - val_accuracy: 0.8853\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 6s 391us/sample - loss: 0.2834 - accuracy: 0.9041 - val_loss: 0.4269 - val_accuracy: 0.8764\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 5s 378us/sample - loss: 0.2739 - accuracy: 0.9082 - val_loss: 0.4452 - val_accuracy: 0.8786\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 5s 379us/sample - loss: 0.2655 - accuracy: 0.9102 - val_loss: 0.4703 - val_accuracy: 0.8741\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 6s 389us/sample - loss: 0.2600 - accuracy: 0.9107 - val_loss: 0.4991 - val_accuracy: 0.8741\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 6s 386us/sample - loss: 0.2537 - accuracy: 0.9122 - val_loss: 0.5410 - val_accuracy: 0.8716\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 5s 380us/sample - loss: 0.2511 - accuracy: 0.9129 - val_loss: 0.5356 - val_accuracy: 0.8730\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 6s 401us/sample - loss: 0.2439 - accuracy: 0.9148 - val_loss: 0.5806 - val_accuracy: 0.8674\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 6s 427us/sample - loss: 0.2376 - accuracy: 0.9162 - val_loss: 0.5901 - val_accuracy: 0.8710\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 6s 398us/sample - loss: 0.2311 - accuracy: 0.9185 - val_loss: 0.6175 - val_accuracy: 0.8696\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 5s 381us/sample - loss: 0.2281 - accuracy: 0.9198 - val_loss: 0.6174 - val_accuracy: 0.8708\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 5s 380us/sample - loss: 0.2230 - accuracy: 0.9229 - val_loss: 0.6050 - val_accuracy: 0.8699\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 5s 382us/sample - loss: 0.2199 - accuracy: 0.9236 - val_loss: 0.6437 - val_accuracy: 0.8674\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 396us/sample - loss: 0.2146 - accuracy: 0.9255 - val_loss: 0.7069 - val_accuracy: 0.8671\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 7s 482us/sample - loss: 0.2143 - accuracy: 0.9240 - val_loss: 0.7078 - val_accuracy: 0.8694\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 6s 393us/sample - loss: 0.2122 - accuracy: 0.9260 - val_loss: 0.6612 - val_accuracy: 0.8682\n",
      "Epoch 28/600\n",
      "14265/14265 [==============================] - 6s 452us/sample - loss: 0.2108 - accuracy: 0.9267 - val_loss: 0.6808 - val_accuracy: 0.8708\n",
      "Epoch 29/600\n",
      "14265/14265 [==============================] - 6s 398us/sample - loss: 0.2056 - accuracy: 0.9284 - val_loss: 0.7229 - val_accuracy: 0.8654\n",
      "Epoch 30/600\n",
      "14265/14265 [==============================] - 6s 413us/sample - loss: 0.2046 - accuracy: 0.9286 - val_loss: 0.6835 - val_accuracy: 0.8663\n",
      "Epoch 31/600\n",
      "14265/14265 [==============================] - 5s 383us/sample - loss: 0.2019 - accuracy: 0.9294 - val_loss: 0.8093 - val_accuracy: 0.8646\n",
      "Epoch 32/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.2002 - accuracy: 0.9305 - val_loss: 0.7518 - val_accuracy: 0.8710\n",
      "Epoch 33/600\n",
      "14265/14265 [==============================] - 6s 446us/sample - loss: 0.1975 - accuracy: 0.9316 - val_loss: 0.8348 - val_accuracy: 0.8632\n",
      "Epoch 34/600\n",
      "14265/14265 [==============================] - 6s 407us/sample - loss: 0.1983 - accuracy: 0.9304 - val_loss: 0.7608 - val_accuracy: 0.8657\n",
      "Epoch 35/600\n",
      "14265/14265 [==============================] - 6s 430us/sample - loss: 0.1959 - accuracy: 0.9318 - val_loss: 0.7718 - val_accuracy: 0.8663\n",
      "Epoch 00035: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 6s 455us/sample - loss: 0.4849 - accuracy: 0.8146 - val_loss: 0.5626 - val_accuracy: 0.8144\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.4817 - accuracy: 0.8146 - val_loss: 0.5559 - val_accuracy: 0.8144\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 6s 416us/sample - loss: 0.4819 - accuracy: 0.8146 - val_loss: 0.5709 - val_accuracy: 0.8144\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 6s 404us/sample - loss: 0.4804 - accuracy: 0.8146 - val_loss: 0.5448 - val_accuracy: 0.8144\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 6s 422us/sample - loss: 0.4767 - accuracy: 0.8146 - val_loss: 0.5222 - val_accuracy: 0.8144\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.4723 - accuracy: 0.8146 - val_loss: 0.5349 - val_accuracy: 0.8144\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.4648 - accuracy: 0.8146 - val_loss: 0.5323 - val_accuracy: 0.8144\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 6s 418us/sample - loss: 0.4536 - accuracy: 0.8146 - val_loss: 0.5260 - val_accuracy: 0.8144.4\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 6s 443us/sample - loss: 0.4459 - accuracy: 0.8146 - val_loss: 0.5364 - val_accuracy: 0.8144\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 6s 390us/sample - loss: 0.4364 - accuracy: 0.8146 - val_loss: 0.5526 - val_accuracy: 0.8144\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 6s 391us/sample - loss: 0.4268 - accuracy: 0.8157 - val_loss: 0.5543 - val_accuracy: 0.8136\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 6s 393us/sample - loss: 0.4141 - accuracy: 0.8182 - val_loss: 0.5738 - val_accuracy: 0.8080\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 6s 452us/sample - loss: 0.4021 - accuracy: 0.8247 - val_loss: 0.5918 - val_accuracy: 0.8012\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 6s 417us/sample - loss: 0.3914 - accuracy: 0.8306 - val_loss: 0.6078 - val_accuracy: 0.8057\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 6s 418us/sample - loss: 0.3785 - accuracy: 0.8392 - val_loss: 0.6308 - val_accuracy: 0.7878\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 6s 424us/sample - loss: 0.3643 - accuracy: 0.8458 - val_loss: 0.6453 - val_accuracy: 0.7816\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 6s 449us/sample - loss: 0.3545 - accuracy: 0.8503 - val_loss: 0.7047 - val_accuracy: 0.7855\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 6s 427us/sample - loss: 0.3465 - accuracy: 0.8545 - val_loss: 0.7172 - val_accuracy: 0.7897\n",
      "Epoch 19/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14265/14265 [==============================] - 6s 392us/sample - loss: 0.3438 - accuracy: 0.8569 - val_loss: 0.7238 - val_accuracy: 0.7886\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 6s 409us/sample - loss: 0.3329 - accuracy: 0.8590 - val_loss: 0.7969 - val_accuracy: 0.7883\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 6s 401us/sample - loss: 0.3306 - accuracy: 0.8618 - val_loss: 0.7712 - val_accuracy: 0.7833\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.3231 - accuracy: 0.8627 - val_loss: 0.8179 - val_accuracy: 0.7844\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 6s 426us/sample - loss: 0.3211 - accuracy: 0.8640 - val_loss: 0.8902 - val_accuracy: 0.7892\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 6s 434us/sample - loss: 0.3159 - accuracy: 0.8663 - val_loss: 0.8399 - val_accuracy: 0.7802\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 400us/sample - loss: 0.3166 - accuracy: 0.8664 - val_loss: 0.9260 - val_accuracy: 0.7855\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 6s 405us/sample - loss: 0.3061 - accuracy: 0.8702 - val_loss: 0.9609 - val_accuracy: 0.7718\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 6s 390us/sample - loss: 0.3059 - accuracy: 0.8706 - val_loss: 0.9364 - val_accuracy: 0.7886\n",
      "Epoch 28/600\n",
      "14265/14265 [==============================] - 6s 393us/sample - loss: 0.3028 - accuracy: 0.8734 - val_loss: 0.9612 - val_accuracy: 0.7883\n",
      "Epoch 29/600\n",
      "14265/14265 [==============================] - 6s 394us/sample - loss: 0.2973 - accuracy: 0.8754 - val_loss: 0.9500 - val_accuracy: 0.7872\n",
      "Epoch 30/600\n",
      "14265/14265 [==============================] - 6s 401us/sample - loss: 0.2989 - accuracy: 0.8725 - val_loss: 0.8914 - val_accuracy: 0.7900\n",
      "Epoch 00030: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 6s 443us/sample - loss: 0.5789 - accuracy: 0.7374 - val_loss: 0.6348 - val_accuracy: 0.7373\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 6s 392us/sample - loss: 0.5777 - accuracy: 0.7374 - val_loss: 0.6178 - val_accuracy: 0.7373\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 6s 399us/sample - loss: 0.5765 - accuracy: 0.7374 - val_loss: 0.6118 - val_accuracy: 0.7373\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 6s 394us/sample - loss: 0.5740 - accuracy: 0.7374 - val_loss: 0.6084 - val_accuracy: 0.7373\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 6s 404us/sample - loss: 0.5702 - accuracy: 0.7374 - val_loss: 0.6111 - val_accuracy: 0.7373\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 400us/sample - loss: 0.5622 - accuracy: 0.7369 - val_loss: 0.6048 - val_accuracy: 0.7373\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 6s 401us/sample - loss: 0.5506 - accuracy: 0.7359 - val_loss: 0.6096 - val_accuracy: 0.7373\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 6s 438us/sample - loss: 0.5320 - accuracy: 0.7399 - val_loss: 0.6208 - val_accuracy: 0.7264\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 6s 399us/sample - loss: 0.5170 - accuracy: 0.7455 - val_loss: 0.6509 - val_accuracy: 0.7034\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 6s 429us/sample - loss: 0.4985 - accuracy: 0.7560 - val_loss: 0.6657 - val_accuracy: 0.7135\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 6s 400us/sample - loss: 0.4789 - accuracy: 0.7677 - val_loss: 0.7125 - val_accuracy: 0.6981\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 6s 403us/sample - loss: 0.4672 - accuracy: 0.7780 - val_loss: 0.7355 - val_accuracy: 0.6894\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 6s 396us/sample - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.7735 - val_accuracy: 0.6933\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 6s 396us/sample - loss: 0.4367 - accuracy: 0.7941 - val_loss: 0.8210 - val_accuracy: 0.6854\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 6s 392us/sample - loss: 0.4283 - accuracy: 0.8010 - val_loss: 0.8262 - val_accuracy: 0.7034\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.4178 - accuracy: 0.8044 - val_loss: 0.8552 - val_accuracy: 0.6899\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 6s 389us/sample - loss: 0.4115 - accuracy: 0.8091 - val_loss: 0.8626 - val_accuracy: 0.6916\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 6s 396us/sample - loss: 0.4062 - accuracy: 0.8088 - val_loss: 0.8640 - val_accuracy: 0.6989\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 6s 386us/sample - loss: 0.4039 - accuracy: 0.8116 - val_loss: 0.9617 - val_accuracy: 0.6925\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 6s 390us/sample - loss: 0.3958 - accuracy: 0.8156 - val_loss: 0.9981 - val_accuracy: 0.6897\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 6s 395us/sample - loss: 0.3945 - accuracy: 0.8177 - val_loss: 0.9428 - val_accuracy: 0.6883\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 6s 391us/sample - loss: 0.3869 - accuracy: 0.8187 - val_loss: 1.0218 - val_accuracy: 0.6967\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 6s 422us/sample - loss: 0.3850 - accuracy: 0.8203 - val_loss: 1.0365 - val_accuracy: 0.6972\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 6s 415us/sample - loss: 0.3830 - accuracy: 0.8223 - val_loss: 1.0291 - val_accuracy: 0.6975\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 411us/sample - loss: 0.3755 - accuracy: 0.8266 - val_loss: 1.0793 - val_accuracy: 0.6939\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 6s 396us/sample - loss: 0.3752 - accuracy: 0.8257 - val_loss: 1.0285 - val_accuracy: 0.6871\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 6s 394us/sample - loss: 0.3709 - accuracy: 0.8273 - val_loss: 1.1236 - val_accuracy: 0.6975\n",
      "Epoch 28/600\n",
      "14265/14265 [==============================] - 6s 407us/sample - loss: 0.3698 - accuracy: 0.8292 - val_loss: 1.0905 - val_accuracy: 0.6919\n",
      "Epoch 29/600\n",
      "14265/14265 [==============================] - 6s 399us/sample - loss: 0.3667 - accuracy: 0.8293 - val_loss: 1.0568 - val_accuracy: 0.6908\n",
      "Epoch 30/600\n",
      "14265/14265 [==============================] - 6s 396us/sample - loss: 0.3677 - accuracy: 0.8286 - val_loss: 1.2304 - val_accuracy: 0.6947\n",
      "Epoch 31/600\n",
      "14265/14265 [==============================] - 5s 383us/sample - loss: 0.3684 - accuracy: 0.8304 - val_loss: 1.0921 - val_accuracy: 0.6888\n",
      "Epoch 00031: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 6s 443us/sample - loss: 0.3168 - accuracy: 0.9112 - val_loss: 0.4445 - val_accuracy: 0.9148\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 6s 390us/sample - loss: 0.2943 - accuracy: 0.9149 - val_loss: 0.4505 - val_accuracy: 0.9148\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 6s 405us/sample - loss: 0.2932 - accuracy: 0.9149 - val_loss: 0.4479 - val_accuracy: 0.9148\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 6s 399us/sample - loss: 0.2935 - accuracy: 0.9149 - val_loss: 0.4222 - val_accuracy: 0.9148\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 6s 409us/sample - loss: 0.2943 - accuracy: 0.9149 - val_loss: 0.4147 - val_accuracy: 0.9148\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 389us/sample - loss: 0.2924 - accuracy: 0.9149 - val_loss: 0.3987 - val_accuracy: 0.9148\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 6s 420us/sample - loss: 0.2922 - accuracy: 0.9149 - val_loss: 0.3908 - val_accuracy: 0.9148\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 6s 417us/sample - loss: 0.2913 - accuracy: 0.9149 - val_loss: 0.3955 - val_accuracy: 0.9148\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 6s 428us/sample - loss: 0.2900 - accuracy: 0.9149 - val_loss: 0.3727 - val_accuracy: 0.9148\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 6s 426us/sample - loss: 0.2861 - accuracy: 0.9149 - val_loss: 0.3736 - val_accuracy: 0.9148\n",
      "Epoch 11/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14265/14265 [==============================] - 6s 402us/sample - loss: 0.2841 - accuracy: 0.9149 - val_loss: 0.3692 - val_accuracy: 0.9148\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 6s 405us/sample - loss: 0.2790 - accuracy: 0.9149 - val_loss: 0.3686 - val_accuracy: 0.9148\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.2741 - accuracy: 0.9149 - val_loss: 0.3721 - val_accuracy: 0.9148\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 6s 403us/sample - loss: 0.2697 - accuracy: 0.9149 - val_loss: 0.3823 - val_accuracy: 0.9148\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 5s 382us/sample - loss: 0.2653 - accuracy: 0.9149 - val_loss: 0.3989 - val_accuracy: 0.9148\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 6s 391us/sample - loss: 0.2622 - accuracy: 0.9149 - val_loss: 0.3937 - val_accuracy: 0.9148\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 6s 393us/sample - loss: 0.2576 - accuracy: 0.9149 - val_loss: 0.4230 - val_accuracy: 0.9148\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 5s 380us/sample - loss: 0.2548 - accuracy: 0.9149 - val_loss: 0.4282 - val_accuracy: 0.9148\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 5s 385us/sample - loss: 0.2534 - accuracy: 0.9149 - val_loss: 0.4381 - val_accuracy: 0.9148\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 6s 388us/sample - loss: 0.2503 - accuracy: 0.9149 - val_loss: 0.4785 - val_accuracy: 0.9148\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 6s 406us/sample - loss: 0.2494 - accuracy: 0.9149 - val_loss: 0.4846 - val_accuracy: 0.9148\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 6s 409us/sample - loss: 0.2458 - accuracy: 0.9149 - val_loss: 0.4935 - val_accuracy: 0.9148\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 6s 442us/sample - loss: 0.2449 - accuracy: 0.9149 - val_loss: 0.5359 - val_accuracy: 0.9148\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 6s 398us/sample - loss: 0.2445 - accuracy: 0.9149 - val_loss: 0.5671 - val_accuracy: 0.9148\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 413us/sample - loss: 0.2426 - accuracy: 0.9149 - val_loss: 0.5265 - val_accuracy: 0.9148\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.2416 - accuracy: 0.9149 - val_loss: 0.5289 - val_accuracy: 0.9148\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 6s 408us/sample - loss: 0.2397 - accuracy: 0.9149 - val_loss: 0.5433 - val_accuracy: 0.9148\n",
      "Epoch 28/600\n",
      "14265/14265 [==============================] - 6s 419us/sample - loss: 0.2390 - accuracy: 0.9149 - val_loss: 0.5432 - val_accuracy: 0.9148\n",
      "Epoch 29/600\n",
      "14265/14265 [==============================] - 6s 407us/sample - loss: 0.2365 - accuracy: 0.9149 - val_loss: 0.5550 - val_accuracy: 0.9148\n",
      "Epoch 30/600\n",
      "14265/14265 [==============================] - 6s 407us/sample - loss: 0.2354 - accuracy: 0.9149 - val_loss: 0.6072 - val_accuracy: 0.9148\n",
      "Epoch 31/600\n",
      "14265/14265 [==============================] - 6s 395us/sample - loss: 0.2361 - accuracy: 0.9149 - val_loss: 0.6029 - val_accuracy: 0.9148\n",
      "Epoch 32/600\n",
      "14265/14265 [==============================] - 6s 399us/sample - loss: 0.2332 - accuracy: 0.9149 - val_loss: 0.5746 - val_accuracy: 0.9148\n",
      "Epoch 33/600\n",
      "14265/14265 [==============================] - 5s 379us/sample - loss: 0.2294 - accuracy: 0.9149 - val_loss: 0.6052 - val_accuracy: 0.9148\n",
      "Epoch 34/600\n",
      "14265/14265 [==============================] - 7s 466us/sample - loss: 0.2294 - accuracy: 0.9149 - val_loss: 0.6365 - val_accuracy: 0.9148\n",
      "Epoch 35/600\n",
      "14265/14265 [==============================] - 11s 776us/sample - loss: 0.2262 - accuracy: 0.9149 - val_loss: 0.6864 - val_accuracy: 0.9148\n",
      "Epoch 36/600\n",
      "14265/14265 [==============================] - 7s 517us/sample - loss: 0.2244 - accuracy: 0.9149 - val_loss: 0.6801 - val_accuracy: 0.9148\n",
      "Epoch 37/600\n",
      "14265/14265 [==============================] - 7s 503us/sample - loss: 0.2208 - accuracy: 0.9149 - val_loss: 0.6502 - val_accuracy: 0.9148\n",
      "Epoch 00037: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 8s 573us/sample - loss: 0.5069 - accuracy: 0.8013 - val_loss: 0.5920 - val_accuracy: 0.8021\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 6s 447us/sample - loss: 0.4986 - accuracy: 0.8022 - val_loss: 0.5919 - val_accuracy: 0.8021\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 6s 453us/sample - loss: 0.4996 - accuracy: 0.8022 - val_loss: 0.5842 - val_accuracy: 0.8021\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 6s 452us/sample - loss: 0.4991 - accuracy: 0.8022 - val_loss: 0.5729 - val_accuracy: 0.8021\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.4998 - accuracy: 0.8022 - val_loss: 0.5586 - val_accuracy: 0.8021\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.4976 - accuracy: 0.8022 - val_loss: 0.5383 - val_accuracy: 0.8021\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 6s 447us/sample - loss: 0.4968 - accuracy: 0.8022 - val_loss: 0.5542 - val_accuracy: 0.8021\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 6s 452us/sample - loss: 0.4922 - accuracy: 0.8022 - val_loss: 0.5388 - val_accuracy: 0.8021\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 7s 460us/sample - loss: 0.4829 - accuracy: 0.8022 - val_loss: 0.5445 - val_accuracy: 0.8021\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 7s 464us/sample - loss: 0.4770 - accuracy: 0.8022 - val_loss: 0.5457 - val_accuracy: 0.8021\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 7s 461us/sample - loss: 0.4646 - accuracy: 0.8018 - val_loss: 0.5466 - val_accuracy: 0.8021\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 6s 456us/sample - loss: 0.4523 - accuracy: 0.8036 - val_loss: 0.5640 - val_accuracy: 0.7869\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 7s 464us/sample - loss: 0.4356 - accuracy: 0.8109 - val_loss: 0.5734 - val_accuracy: 0.7909\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 7s 472us/sample - loss: 0.4183 - accuracy: 0.8206 - val_loss: 0.5912 - val_accuracy: 0.7715\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.4054 - accuracy: 0.8287 - val_loss: 0.6097 - val_accuracy: 0.7796\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 7s 508us/sample - loss: 0.3925 - accuracy: 0.8337 - val_loss: 0.6406 - val_accuracy: 0.7634\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 7s 503us/sample - loss: 0.3807 - accuracy: 0.8412 - val_loss: 0.6553 - val_accuracy: 0.7547\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 7s 489us/sample - loss: 0.3697 - accuracy: 0.8473 - val_loss: 0.6967 - val_accuracy: 0.7656\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 7s 462us/sample - loss: 0.3587 - accuracy: 0.8521 - val_loss: 0.7296 - val_accuracy: 0.7687\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 7s 459us/sample - loss: 0.3529 - accuracy: 0.8541 - val_loss: 0.7440 - val_accuracy: 0.7564\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 7s 508us/sample - loss: 0.3476 - accuracy: 0.8561 - val_loss: 0.7806 - val_accuracy: 0.7665\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 7s 477us/sample - loss: 0.3428 - accuracy: 0.8576 - val_loss: 0.7845 - val_accuracy: 0.7637\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 7s 473us/sample - loss: 0.3318 - accuracy: 0.8625 - val_loss: 0.9339 - val_accuracy: 0.7710\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.3300 - accuracy: 0.8637 - val_loss: 0.8792 - val_accuracy: 0.7555\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.3267 - accuracy: 0.8656 - val_loss: 0.8745 - val_accuracy: 0.7508\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 6s 453us/sample - loss: 0.3225 - accuracy: 0.8660 - val_loss: 0.9241 - val_accuracy: 0.7578\n",
      "Epoch 27/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14265/14265 [==============================] - 7s 457us/sample - loss: 0.3182 - accuracy: 0.8693 - val_loss: 0.9462 - val_accuracy: 0.7673\n",
      "Epoch 28/600\n",
      "14265/14265 [==============================] - 7s 463us/sample - loss: 0.3138 - accuracy: 0.8693 - val_loss: 0.9956 - val_accuracy: 0.7645\n",
      "Epoch 29/600\n",
      "14265/14265 [==============================] - 7s 517us/sample - loss: 0.3085 - accuracy: 0.8728 - val_loss: 0.9691 - val_accuracy: 0.7555\n",
      "Epoch 30/600\n",
      "14265/14265 [==============================] - 7s 491us/sample - loss: 0.3093 - accuracy: 0.8735 - val_loss: 1.0789 - val_accuracy: 0.7620\n",
      "Epoch 31/600\n",
      "14265/14265 [==============================] - 7s 481us/sample - loss: 0.3031 - accuracy: 0.8753 - val_loss: 1.0656 - val_accuracy: 0.7561\n",
      "Epoch 00031: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 8s 542us/sample - loss: 0.6587 - accuracy: 0.6346 - val_loss: 0.6607 - val_accuracy: 0.6414\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 7s 485us/sample - loss: 0.6529 - accuracy: 0.6414 - val_loss: 0.6579 - val_accuracy: 0.6414\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 7s 492us/sample - loss: 0.6527 - accuracy: 0.6413 - val_loss: 0.6605 - val_accuracy: 0.6420\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 7s 472us/sample - loss: 0.6481 - accuracy: 0.6442 - val_loss: 0.6604 - val_accuracy: 0.6355\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 7s 466us/sample - loss: 0.6402 - accuracy: 0.6540 - val_loss: 0.6598 - val_accuracy: 0.6266\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 7s 487us/sample - loss: 0.6247 - accuracy: 0.6713 - val_loss: 0.6682 - val_accuracy: 0.6148\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 6s 452us/sample - loss: 0.6051 - accuracy: 0.6932 - val_loss: 0.6829 - val_accuracy: 0.6100\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 6s 455us/sample - loss: 0.5835 - accuracy: 0.7040 - val_loss: 0.6889 - val_accuracy: 0.6134\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 7s 469us/sample - loss: 0.5627 - accuracy: 0.7152 - val_loss: 0.7087 - val_accuracy: 0.6109\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 7s 479us/sample - loss: 0.5448 - accuracy: 0.7204 - val_loss: 0.7502 - val_accuracy: 0.6184\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 7s 464us/sample - loss: 0.5310 - accuracy: 0.7309 - val_loss: 0.7983 - val_accuracy: 0.6128\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 7s 499us/sample - loss: 0.5134 - accuracy: 0.7363 - val_loss: 0.8105 - val_accuracy: 0.6036\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 7s 499us/sample - loss: 0.5017 - accuracy: 0.7411 - val_loss: 0.8384 - val_accuracy: 0.6095\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 7s 481us/sample - loss: 0.4905 - accuracy: 0.7429 - val_loss: 0.8731 - val_accuracy: 0.6109\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 7s 467us/sample - loss: 0.4833 - accuracy: 0.7501 - val_loss: 0.9064 - val_accuracy: 0.6103\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 7s 509us/sample - loss: 0.4746 - accuracy: 0.7563 - val_loss: 0.9061 - val_accuracy: 0.6154\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 7s 517us/sample - loss: 0.4686 - accuracy: 0.7567 - val_loss: 0.9426 - val_accuracy: 0.6120\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 7s 516us/sample - loss: 0.4599 - accuracy: 0.7624 - val_loss: 0.9951 - val_accuracy: 0.6126\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 7s 457us/sample - loss: 0.4571 - accuracy: 0.7629 - val_loss: 1.0080 - val_accuracy: 0.6128\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 7s 480us/sample - loss: 0.4515 - accuracy: 0.7659 - val_loss: 1.0109 - val_accuracy: 0.6089\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 7s 478us/sample - loss: 0.4489 - accuracy: 0.7662 - val_loss: 1.0713 - val_accuracy: 0.6084\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 7s 473us/sample - loss: 0.4465 - accuracy: 0.7696 - val_loss: 1.0667 - val_accuracy: 0.6011\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 7s 500us/sample - loss: 0.4380 - accuracy: 0.7712 - val_loss: 1.1585 - val_accuracy: 0.6039\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 7s 488us/sample - loss: 0.4386 - accuracy: 0.7716 - val_loss: 1.0928 - val_accuracy: 0.6050\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 7s 481us/sample - loss: 0.4341 - accuracy: 0.7755 - val_loss: 1.1676 - val_accuracy: 0.6022\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 7s 496us/sample - loss: 0.4294 - accuracy: 0.7762 - val_loss: 1.2079 - val_accuracy: 0.5997\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 6s 454us/sample - loss: 0.4306 - accuracy: 0.7755 - val_loss: 1.2276 - val_accuracy: 0.6027\n",
      "Epoch 00027: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 7s 509us/sample - loss: 0.3965 - accuracy: 0.8726 - val_loss: 0.4640 - val_accuracy: 0.8867\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 7s 467us/sample - loss: 0.3549 - accuracy: 0.8867 - val_loss: 0.4592 - val_accuracy: 0.8867\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 7s 469us/sample - loss: 0.3548 - accuracy: 0.8867 - val_loss: 0.4827 - val_accuracy: 0.8867\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 6s 452us/sample - loss: 0.3545 - accuracy: 0.8867 - val_loss: 0.4793 - val_accuracy: 0.8867\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 7s 461us/sample - loss: 0.3544 - accuracy: 0.8867 - val_loss: 0.4675 - val_accuracy: 0.8867\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 455us/sample - loss: 0.3543 - accuracy: 0.8867 - val_loss: 0.4615 - val_accuracy: 0.8867\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 6s 454us/sample - loss: 0.3547 - accuracy: 0.8867 - val_loss: 0.4394 - val_accuracy: 0.8867\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 7s 460us/sample - loss: 0.3530 - accuracy: 0.8866 - val_loss: 0.4573 - val_accuracy: 0.8865\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 7s 477us/sample - loss: 0.3468 - accuracy: 0.8877 - val_loss: 0.4547 - val_accuracy: 0.8778\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 7s 483us/sample - loss: 0.3383 - accuracy: 0.8894 - val_loss: 0.4666 - val_accuracy: 0.8677\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 6s 453us/sample - loss: 0.3275 - accuracy: 0.8952 - val_loss: 0.4767 - val_accuracy: 0.8623\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 7s 468us/sample - loss: 0.3192 - accuracy: 0.8978 - val_loss: 0.4964 - val_accuracy: 0.8511\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 6s 450us/sample - loss: 0.3144 - accuracy: 0.9016 - val_loss: 0.4656 - val_accuracy: 0.8604\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 6s 454us/sample - loss: 0.3065 - accuracy: 0.9040 - val_loss: 0.4818 - val_accuracy: 0.8576\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 6s 449us/sample - loss: 0.3024 - accuracy: 0.9063 - val_loss: 0.4837 - val_accuracy: 0.8581\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 6s 455us/sample - loss: 0.3003 - accuracy: 0.9066 - val_loss: 0.4893 - val_accuracy: 0.8573\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 7s 469us/sample - loss: 0.2961 - accuracy: 0.9088 - val_loss: 0.4976 - val_accuracy: 0.8539\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 7s 465us/sample - loss: 0.2927 - accuracy: 0.9094 - val_loss: 0.4891 - val_accuracy: 0.8556\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 7s 468us/sample - loss: 0.2898 - accuracy: 0.9101 - val_loss: 0.5119 - val_accuracy: 0.8492\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 7s 493us/sample - loss: 0.2885 - accuracy: 0.9110 - val_loss: 0.4776 - val_accuracy: 0.8573\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 7s 458us/sample - loss: 0.2857 - accuracy: 0.9117 - val_loss: 0.4953 - val_accuracy: 0.8579\n",
      "Epoch 22/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14265/14265 [==============================] - 6s 450us/sample - loss: 0.2812 - accuracy: 0.9118 - val_loss: 0.4849 - val_accuracy: 0.8570\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 7s 462us/sample - loss: 0.2795 - accuracy: 0.9134 - val_loss: 0.4783 - val_accuracy: 0.8595\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 7s 475us/sample - loss: 0.2766 - accuracy: 0.9129 - val_loss: 0.4909 - val_accuracy: 0.8559\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.2726 - accuracy: 0.9132 - val_loss: 0.4987 - val_accuracy: 0.8584\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 6s 454us/sample - loss: 0.2695 - accuracy: 0.9145 - val_loss: 0.4726 - val_accuracy: 0.8632\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 7s 458us/sample - loss: 0.2639 - accuracy: 0.9153 - val_loss: 0.5348 - val_accuracy: 0.8537\n",
      "Epoch 28/600\n",
      "14265/14265 [==============================] - 7s 504us/sample - loss: 0.2620 - accuracy: 0.9162 - val_loss: 0.4918 - val_accuracy: 0.8598\n",
      "Epoch 29/600\n",
      "14265/14265 [==============================] - 6s 454us/sample - loss: 0.2593 - accuracy: 0.9169 - val_loss: 0.5012 - val_accuracy: 0.8598\n",
      "Epoch 30/600\n",
      "14265/14265 [==============================] - 7s 473us/sample - loss: 0.2552 - accuracy: 0.9174 - val_loss: 0.5289 - val_accuracy: 0.8593\n",
      "Epoch 31/600\n",
      "14265/14265 [==============================] - 7s 466us/sample - loss: 0.2498 - accuracy: 0.9166 - val_loss: 0.5167 - val_accuracy: 0.8593\n",
      "Epoch 32/600\n",
      "14265/14265 [==============================] - 7s 457us/sample - loss: 0.2481 - accuracy: 0.9180 - val_loss: 0.5174 - val_accuracy: 0.8612\n",
      "Epoch 00032: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 7s 520us/sample - loss: 0.6528 - accuracy: 0.6440 - val_loss: 0.6531 - val_accuracy: 0.6510\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 6s 449us/sample - loss: 0.6475 - accuracy: 0.6508 - val_loss: 0.6518 - val_accuracy: 0.6510\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 7s 459us/sample - loss: 0.6477 - accuracy: 0.6508 - val_loss: 0.6546 - val_accuracy: 0.6510\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.6467 - accuracy: 0.6502 - val_loss: 0.6520 - val_accuracy: 0.6510\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 7s 464us/sample - loss: 0.6415 - accuracy: 0.6547 - val_loss: 0.6527 - val_accuracy: 0.6501\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.6322 - accuracy: 0.6642 - val_loss: 0.6556 - val_accuracy: 0.6392\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 6s 450us/sample - loss: 0.6156 - accuracy: 0.6783 - val_loss: 0.6628 - val_accuracy: 0.6330\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 6s 450us/sample - loss: 0.5959 - accuracy: 0.6920 - val_loss: 0.6680 - val_accuracy: 0.6294\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 6s 453us/sample - loss: 0.5750 - accuracy: 0.7047 - val_loss: 0.6823 - val_accuracy: 0.6313\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.5555 - accuracy: 0.7162 - val_loss: 0.7036 - val_accuracy: 0.6277\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 6s 446us/sample - loss: 0.5340 - accuracy: 0.7253 - val_loss: 0.7238 - val_accuracy: 0.6241\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 7s 456us/sample - loss: 0.5150 - accuracy: 0.7333 - val_loss: 0.7612 - val_accuracy: 0.6159\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 7s 464us/sample - loss: 0.5054 - accuracy: 0.7396 - val_loss: 0.7826 - val_accuracy: 0.6213\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 6s 453us/sample - loss: 0.4931 - accuracy: 0.7489 - val_loss: 0.8239 - val_accuracy: 0.6165\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 7s 462us/sample - loss: 0.4826 - accuracy: 0.7523 - val_loss: 0.8518 - val_accuracy: 0.6173\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 7s 465us/sample - loss: 0.4722 - accuracy: 0.7582 - val_loss: 0.8724 - val_accuracy: 0.6184\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 6s 447us/sample - loss: 0.4696 - accuracy: 0.7567 - val_loss: 0.9329 - val_accuracy: 0.6165\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 6s 450us/sample - loss: 0.4588 - accuracy: 0.7613 - val_loss: 0.9559 - val_accuracy: 0.6187\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 7s 463us/sample - loss: 0.4582 - accuracy: 0.7628 - val_loss: 0.9714 - val_accuracy: 0.6142\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 7s 463us/sample - loss: 0.4486 - accuracy: 0.7694 - val_loss: 1.0118 - val_accuracy: 0.6126\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.4476 - accuracy: 0.7680 - val_loss: 1.0324 - val_accuracy: 0.6078\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 7s 465us/sample - loss: 0.4420 - accuracy: 0.7725 - val_loss: 1.0813 - val_accuracy: 0.6159\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 6s 452us/sample - loss: 0.4434 - accuracy: 0.7727 - val_loss: 1.0461 - val_accuracy: 0.6168\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 6s 448us/sample - loss: 0.4395 - accuracy: 0.7734 - val_loss: 1.0350 - val_accuracy: 0.6179\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 453us/sample - loss: 0.4311 - accuracy: 0.7774 - val_loss: 1.0520 - val_accuracy: 0.6173\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 6s 453us/sample - loss: 0.4326 - accuracy: 0.7781 - val_loss: 1.0932 - val_accuracy: 0.6179\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 7s 458us/sample - loss: 0.4309 - accuracy: 0.7806 - val_loss: 1.1113 - val_accuracy: 0.6148\n",
      "Epoch 00027: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 7s 513us/sample - loss: 0.5630 - accuracy: 0.7528 - val_loss: 0.6092 - val_accuracy: 0.7527\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 6s 453us/sample - loss: 0.5613 - accuracy: 0.7529 - val_loss: 0.6013 - val_accuracy: 0.7527\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 6s 453us/sample - loss: 0.5601 - accuracy: 0.7529 - val_loss: 0.5862 - val_accuracy: 0.7527\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 7s 470us/sample - loss: 0.5589 - accuracy: 0.7527 - val_loss: 0.5943 - val_accuracy: 0.7527\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 6s 454us/sample - loss: 0.5550 - accuracy: 0.7526 - val_loss: 0.5883 - val_accuracy: 0.7527\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 451us/sample - loss: 0.5459 - accuracy: 0.7527 - val_loss: 0.5805 - val_accuracy: 0.7525\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 7s 466us/sample - loss: 0.5341 - accuracy: 0.7546 - val_loss: 0.5913 - val_accuracy: 0.7396\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 7s 522us/sample - loss: 0.5155 - accuracy: 0.7628 - val_loss: 0.6039 - val_accuracy: 0.7323\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 7s 480us/sample - loss: 0.4954 - accuracy: 0.7721 - val_loss: 0.6214 - val_accuracy: 0.7309\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 7s 502us/sample - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.6388 - val_accuracy: 0.7303\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 7s 479us/sample - loss: 0.4607 - accuracy: 0.7917 - val_loss: 0.6634 - val_accuracy: 0.7233\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 8s 530us/sample - loss: 0.4463 - accuracy: 0.7979 - val_loss: 0.6832 - val_accuracy: 0.7199\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 8s 543us/sample - loss: 0.4306 - accuracy: 0.8060 - val_loss: 0.7045 - val_accuracy: 0.7199\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 7s 460us/sample - loss: 0.4209 - accuracy: 0.8100 - val_loss: 0.7425 - val_accuracy: 0.7183\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 7s 477us/sample - loss: 0.4124 - accuracy: 0.8132 - val_loss: 0.7636 - val_accuracy: 0.7126\n",
      "Epoch 16/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14265/14265 [==============================] - 7s 461us/sample - loss: 0.4043 - accuracy: 0.8175 - val_loss: 0.8024 - val_accuracy: 0.7157\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 8s 548us/sample - loss: 0.3926 - accuracy: 0.8235 - val_loss: 0.8581 - val_accuracy: 0.7205\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 8s 529us/sample - loss: 0.3879 - accuracy: 0.8261 - val_loss: 0.8986 - val_accuracy: 0.7160\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 8s 551us/sample - loss: 0.3840 - accuracy: 0.8273 - val_loss: 0.8854 - val_accuracy: 0.7129\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 7s 483us/sample - loss: 0.3781 - accuracy: 0.8287 - val_loss: 0.9163 - val_accuracy: 0.7110\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 7s 463us/sample - loss: 0.3752 - accuracy: 0.8321 - val_loss: 0.9190 - val_accuracy: 0.7107\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 7s 483us/sample - loss: 0.3708 - accuracy: 0.8343 - val_loss: 0.9347 - val_accuracy: 0.7183\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 8s 542us/sample - loss: 0.3653 - accuracy: 0.8361 - val_loss: 0.9594 - val_accuracy: 0.7115\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 7s 460us/sample - loss: 0.3628 - accuracy: 0.8391 - val_loss: 0.9767 - val_accuracy: 0.7168\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 403us/sample - loss: 0.3606 - accuracy: 0.8377 - val_loss: 0.9668 - val_accuracy: 0.7208\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 6s 405us/sample - loss: 0.3533 - accuracy: 0.8401 - val_loss: 1.0573 - val_accuracy: 0.7054\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 6s 440us/sample - loss: 0.3544 - accuracy: 0.8409 - val_loss: 1.0258 - val_accuracy: 0.7070\n",
      "Epoch 28/600\n",
      "14265/14265 [==============================] - 6s 391us/sample - loss: 0.3508 - accuracy: 0.8400 - val_loss: 1.0485 - val_accuracy: 0.7090\n",
      "Epoch 29/600\n",
      "14265/14265 [==============================] - 6s 393us/sample - loss: 0.3476 - accuracy: 0.8444 - val_loss: 1.0379 - val_accuracy: 0.7104\n",
      "Epoch 30/600\n",
      "14265/14265 [==============================] - 6s 416us/sample - loss: 0.3467 - accuracy: 0.8426 - val_loss: 1.1779 - val_accuracy: 0.7093\n",
      "Epoch 31/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.3438 - accuracy: 0.8463 - val_loss: 1.0828 - val_accuracy: 0.7118\n",
      "Epoch 00031: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n",
      "14265/14265 [==============================] - 6s 440us/sample - loss: 0.3286 - accuracy: 0.9056 - val_loss: 0.4966 - val_accuracy: 0.9092\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 6s 401us/sample - loss: 0.3075 - accuracy: 0.9090 - val_loss: 0.4956 - val_accuracy: 0.9092\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 6s 388us/sample - loss: 0.3068 - accuracy: 0.9090 - val_loss: 0.4834 - val_accuracy: 0.9092\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 6s 406us/sample - loss: 0.3065 - accuracy: 0.9090 - val_loss: 0.4603 - val_accuracy: 0.9092\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 6s 420us/sample - loss: 0.3065 - accuracy: 0.9090 - val_loss: 0.4517 - val_accuracy: 0.9092\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 416us/sample - loss: 0.3063 - accuracy: 0.9090 - val_loss: 0.4514 - val_accuracy: 0.9092\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 6s 404us/sample - loss: 0.3055 - accuracy: 0.9090 - val_loss: 0.4414 - val_accuracy: 0.9092\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 6s 409us/sample - loss: 0.3040 - accuracy: 0.9090 - val_loss: 0.4411 - val_accuracy: 0.9092\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 6s 412us/sample - loss: 0.3006 - accuracy: 0.9087 - val_loss: 0.3998 - val_accuracy: 0.9075\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 6s 414us/sample - loss: 0.2926 - accuracy: 0.9092 - val_loss: 0.3995 - val_accuracy: 0.9008\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 6s 416us/sample - loss: 0.2805 - accuracy: 0.9125 - val_loss: 0.4085 - val_accuracy: 0.8873\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 6s 398us/sample - loss: 0.2689 - accuracy: 0.9156 - val_loss: 0.3885 - val_accuracy: 0.8926\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 5s 385us/sample - loss: 0.2604 - accuracy: 0.9188 - val_loss: 0.4016 - val_accuracy: 0.8907\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 5s 383us/sample - loss: 0.2526 - accuracy: 0.9215 - val_loss: 0.4030 - val_accuracy: 0.8893\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 6s 404us/sample - loss: 0.2435 - accuracy: 0.9234 - val_loss: 0.4296 - val_accuracy: 0.8837\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 5s 381us/sample - loss: 0.2379 - accuracy: 0.9239 - val_loss: 0.4336 - val_accuracy: 0.8907\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 6s 388us/sample - loss: 0.2294 - accuracy: 0.9274 - val_loss: 0.4641 - val_accuracy: 0.8856\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 5s 384us/sample - loss: 0.2252 - accuracy: 0.9267 - val_loss: 0.4676 - val_accuracy: 0.8867\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 5s 380us/sample - loss: 0.2216 - accuracy: 0.9288 - val_loss: 0.4829 - val_accuracy: 0.8834\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 5s 383us/sample - loss: 0.2149 - accuracy: 0.9300 - val_loss: 0.5154 - val_accuracy: 0.8884\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 5s 380us/sample - loss: 0.2122 - accuracy: 0.9309 - val_loss: 0.5374 - val_accuracy: 0.8839\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 6s 406us/sample - loss: 0.2094 - accuracy: 0.9319 - val_loss: 0.5794 - val_accuracy: 0.8876\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 6s 394us/sample - loss: 0.2064 - accuracy: 0.9312 - val_loss: 0.5919 - val_accuracy: 0.8912\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 6s 392us/sample - loss: 0.2048 - accuracy: 0.9331 - val_loss: 0.5845 - val_accuracy: 0.8884\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 387us/sample - loss: 0.2020 - accuracy: 0.9339 - val_loss: 0.5991 - val_accuracy: 0.8853\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 6s 402us/sample - loss: 0.2000 - accuracy: 0.9334 - val_loss: 0.6308 - val_accuracy: 0.8879\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.1982 - accuracy: 0.9347 - val_loss: 0.6309 - val_accuracy: 0.8884\n",
      "Epoch 28/600\n",
      "14265/14265 [==============================] - 6s 386us/sample - loss: 0.1936 - accuracy: 0.9353 - val_loss: 0.6729 - val_accuracy: 0.8895\n",
      "Epoch 29/600\n",
      "14265/14265 [==============================] - 6s 401us/sample - loss: 0.1933 - accuracy: 0.9371 - val_loss: 0.6498 - val_accuracy: 0.8831\n",
      "Epoch 30/600\n",
      "14265/14265 [==============================] - 6s 407us/sample - loss: 0.1911 - accuracy: 0.9366 - val_loss: 0.6475 - val_accuracy: 0.8820\n",
      "Epoch 31/600\n",
      "14265/14265 [==============================] - 6s 406us/sample - loss: 0.1889 - accuracy: 0.9375 - val_loss: 0.6888 - val_accuracy: 0.8921\n",
      "Epoch 32/600\n",
      "14265/14265 [==============================] - 6s 402us/sample - loss: 0.1860 - accuracy: 0.9389 - val_loss: 0.7341 - val_accuracy: 0.8890\n",
      "Epoch 33/600\n",
      "14265/14265 [==============================] - 6s 396us/sample - loss: 0.1866 - accuracy: 0.9380 - val_loss: 0.6817 - val_accuracy: 0.8842\n",
      "Epoch 34/600\n",
      "14265/14265 [==============================] - 6s 397us/sample - loss: 0.1825 - accuracy: 0.9389 - val_loss: 0.7883 - val_accuracy: 0.8890\n",
      "Epoch 35/600\n",
      "14265/14265 [==============================] - 6s 396us/sample - loss: 0.1818 - accuracy: 0.9399 - val_loss: 0.7418 - val_accuracy: 0.8867\n",
      "Epoch 36/600\n",
      "14265/14265 [==============================] - 6s 394us/sample - loss: 0.1823 - accuracy: 0.9398 - val_loss: 0.7213 - val_accuracy: 0.8870\n",
      "Epoch 37/600\n",
      "14265/14265 [==============================] - 6s 389us/sample - loss: 0.1806 - accuracy: 0.9400 - val_loss: 0.7350 - val_accuracy: 0.8853\n",
      "Epoch 00037: early stopping\n",
      "Train on 14265 samples, validate on 3567 samples\n",
      "Epoch 1/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14265/14265 [==============================] - 7s 478us/sample - loss: 0.2198 - accuracy: 0.9488 - val_loss: 0.3303 - val_accuracy: 0.9540\n",
      "Epoch 2/600\n",
      "14265/14265 [==============================] - 6s 398us/sample - loss: 0.1895 - accuracy: 0.9541 - val_loss: 0.3557 - val_accuracy: 0.9540\n",
      "Epoch 3/600\n",
      "14265/14265 [==============================] - 6s 417us/sample - loss: 0.1883 - accuracy: 0.9541 - val_loss: 0.3438 - val_accuracy: 0.9540\n",
      "Epoch 4/600\n",
      "14265/14265 [==============================] - 6s 417us/sample - loss: 0.1884 - accuracy: 0.9541 - val_loss: 0.3506 - val_accuracy: 0.9540\n",
      "Epoch 5/600\n",
      "14265/14265 [==============================] - 6s 412us/sample - loss: 0.1887 - accuracy: 0.9541 - val_loss: 0.3408 - val_accuracy: 0.9540\n",
      "Epoch 6/600\n",
      "14265/14265 [==============================] - 6s 446us/sample - loss: 0.1876 - accuracy: 0.9541 - val_loss: 0.3141 - val_accuracy: 0.9540\n",
      "Epoch 7/600\n",
      "14265/14265 [==============================] - 6s 428us/sample - loss: 0.1891 - accuracy: 0.9541 - val_loss: 0.3294 - val_accuracy: 0.9540\n",
      "Epoch 8/600\n",
      "14265/14265 [==============================] - 6s 417us/sample - loss: 0.1872 - accuracy: 0.9541 - val_loss: 0.3005 - val_accuracy: 0.9540\n",
      "Epoch 9/600\n",
      "14265/14265 [==============================] - 7s 472us/sample - loss: 0.1872 - accuracy: 0.9541 - val_loss: 0.3311 - val_accuracy: 0.9540\n",
      "Epoch 10/600\n",
      "14265/14265 [==============================] - 6s 398us/sample - loss: 0.1851 - accuracy: 0.9541 - val_loss: 0.2917 - val_accuracy: 0.9540\n",
      "Epoch 11/600\n",
      "14265/14265 [==============================] - 6s 416us/sample - loss: 0.1840 - accuracy: 0.9541 - val_loss: 0.2650 - val_accuracy: 0.9540\n",
      "Epoch 12/600\n",
      "14265/14265 [==============================] - 8s 559us/sample - loss: 0.1824 - accuracy: 0.9541 - val_loss: 0.2684 - val_accuracy: 0.9540\n",
      "Epoch 13/600\n",
      "14265/14265 [==============================] - 6s 436us/sample - loss: 0.1800 - accuracy: 0.9541 - val_loss: 0.2782 - val_accuracy: 0.9540\n",
      "Epoch 14/600\n",
      "14265/14265 [==============================] - 6s 417us/sample - loss: 0.1766 - accuracy: 0.9541 - val_loss: 0.2699 - val_accuracy: 0.9540\n",
      "Epoch 15/600\n",
      "14265/14265 [==============================] - 6s 416us/sample - loss: 0.1726 - accuracy: 0.9541 - val_loss: 0.2650 - val_accuracy: 0.9540\n",
      "Epoch 16/600\n",
      "14265/14265 [==============================] - 6s 410us/sample - loss: 0.1697 - accuracy: 0.9541 - val_loss: 0.2804 - val_accuracy: 0.9540\n",
      "Epoch 17/600\n",
      "14265/14265 [==============================] - 6s 416us/sample - loss: 0.1661 - accuracy: 0.9541 - val_loss: 0.2810 - val_accuracy: 0.9540\n",
      "Epoch 18/600\n",
      "14265/14265 [==============================] - 6s 426us/sample - loss: 0.1647 - accuracy: 0.9541 - val_loss: 0.2936 - val_accuracy: 0.9540\n",
      "Epoch 19/600\n",
      "14265/14265 [==============================] - 6s 429us/sample - loss: 0.1634 - accuracy: 0.9541 - val_loss: 0.2885 - val_accuracy: 0.9540\n",
      "Epoch 20/600\n",
      "14265/14265 [==============================] - 6s 415us/sample - loss: 0.1614 - accuracy: 0.9541 - val_loss: 0.2963 - val_accuracy: 0.9540\n",
      "Epoch 21/600\n",
      "14265/14265 [==============================] - 6s 409us/sample - loss: 0.1573 - accuracy: 0.9540 - val_loss: 0.3368 - val_accuracy: 0.9540\n",
      "Epoch 22/600\n",
      "14265/14265 [==============================] - 6s 409us/sample - loss: 0.1565 - accuracy: 0.9539 - val_loss: 0.3303 - val_accuracy: 0.9540\n",
      "Epoch 23/600\n",
      "14265/14265 [==============================] - 6s 431us/sample - loss: 0.1509 - accuracy: 0.9544 - val_loss: 0.3603 - val_accuracy: 0.9540\n",
      "Epoch 24/600\n",
      "14265/14265 [==============================] - 6s 391us/sample - loss: 0.1474 - accuracy: 0.9548 - val_loss: 0.3565 - val_accuracy: 0.9526\n",
      "Epoch 25/600\n",
      "14265/14265 [==============================] - 6s 389us/sample - loss: 0.1424 - accuracy: 0.9563 - val_loss: 0.3689 - val_accuracy: 0.9523\n",
      "Epoch 26/600\n",
      "14265/14265 [==============================] - 6s 399us/sample - loss: 0.1346 - accuracy: 0.9589 - val_loss: 0.4085 - val_accuracy: 0.9495\n",
      "Epoch 27/600\n",
      "14265/14265 [==============================] - 6s 388us/sample - loss: 0.1313 - accuracy: 0.9591 - val_loss: 0.4163 - val_accuracy: 0.9473\n",
      "Epoch 28/600\n",
      "14265/14265 [==============================] - 5s 381us/sample - loss: 0.1256 - accuracy: 0.9625 - val_loss: 0.4668 - val_accuracy: 0.9453\n",
      "Epoch 29/600\n",
      "14265/14265 [==============================] - 6s 419us/sample - loss: 0.1256 - accuracy: 0.9621 - val_loss: 0.4594 - val_accuracy: 0.9431\n",
      "Epoch 30/600\n",
      "14265/14265 [==============================] - 6s 410us/sample - loss: 0.1225 - accuracy: 0.9620 - val_loss: 0.4888 - val_accuracy: 0.9487\n",
      "Epoch 31/600\n",
      "14265/14265 [==============================] - 7s 460us/sample - loss: 0.1177 - accuracy: 0.9648 - val_loss: 0.4881 - val_accuracy: 0.9403\n",
      "Epoch 32/600\n",
      "14265/14265 [==============================] - 6s 401us/sample - loss: 0.1151 - accuracy: 0.9658 - val_loss: 0.4805 - val_accuracy: 0.9403\n",
      "Epoch 33/600\n",
      "14265/14265 [==============================] - 6s 400us/sample - loss: 0.1124 - accuracy: 0.9663 - val_loss: 0.5042 - val_accuracy: 0.9417\n",
      "Epoch 34/600\n",
      "14265/14265 [==============================] - 6s 429us/sample - loss: 0.1138 - accuracy: 0.9660 - val_loss: 0.5567 - val_accuracy: 0.9445\n",
      "Epoch 35/600\n",
      "14265/14265 [==============================] - 6s 419us/sample - loss: 0.1109 - accuracy: 0.9673 - val_loss: 0.5601 - val_accuracy: 0.9417\n",
      "Epoch 36/600\n",
      "14265/14265 [==============================] - 6s 429us/sample - loss: 0.1087 - accuracy: 0.9678 - val_loss: 0.5634 - val_accuracy: 0.9437\n",
      "Epoch 00036: early stopping\n"
     ]
    }
   ],
   "source": [
    "for topic in topic_cols:\n",
    "    topics_text_vectors = topics[['goal_name_clean_NV_LoW', topic]]\n",
    "    topics_text_vectors.dropna(inplace=True)\n",
    "    text = topics_text_vectors['goal_name_clean_NV_LoW']\n",
    "    y = topics_text_vectors[topic]\n",
    "    token = Tokenizer()\n",
    "    token.fit_on_texts(text)\n",
    "    vocab_size = len(token.word_index) + 1\n",
    "    encoded_text = token.texts_to_sequences(text)\n",
    "    max_len = int()\n",
    "    for i in encoded_text:\n",
    "        len_ = len(i)\n",
    "        if len_ > max_len:\n",
    "            max_len = len_\n",
    "    X = pad_sequences(encoded_text, maxlen=max_len, padding='post')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "    model = create_model()\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test= np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "    model.fit(X_train, y_train, epochs=600, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "    name = topic.split('_')[-1]\n",
    "    model.save(f\"../models/topics_goal_name/goal_{name}_vect_nn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
