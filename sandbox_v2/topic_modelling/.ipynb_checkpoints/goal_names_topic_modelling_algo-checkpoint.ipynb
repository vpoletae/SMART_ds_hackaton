{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = pd.read_csv('../joint_clean_data/topics.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal_id</th>\n",
       "      <th>goal_domain_original</th>\n",
       "      <th>goal_name_type_original</th>\n",
       "      <th>goal_domain_LoW</th>\n",
       "      <th>goal_name_type_LoW</th>\n",
       "      <th>goal_domain_no_noise</th>\n",
       "      <th>goal_name_type_no_noise</th>\n",
       "      <th>goal_domain_mean_pos</th>\n",
       "      <th>goal_name_type_mean_pos</th>\n",
       "      <th>remove</th>\n",
       "      <th>...</th>\n",
       "      <th>label_attractor_hard_skill</th>\n",
       "      <th>label_attractor_soft_skill</th>\n",
       "      <th>label_attractor_tool</th>\n",
       "      <th>label_attractor_community</th>\n",
       "      <th>label_attractor_subjectivity</th>\n",
       "      <th>label_attractor_habits</th>\n",
       "      <th>label_attractor_career</th>\n",
       "      <th>label_attractor_fixing</th>\n",
       "      <th>label_attractor_art</th>\n",
       "      <th>label_attractor_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>творчество и создание нового изобразительное и...</td>\n",
       "      <td>не отстать от поезда современности получить зн...</td>\n",
       "      <td>['творчество', 'и', 'создание', 'нового', 'изо...</td>\n",
       "      <td>['не', 'отстать', 'от', 'поезда', 'современнос...</td>\n",
       "      <td>творчество создание новое изобразительный иску...</td>\n",
       "      <td>отстать поезд современность получить знание но...</td>\n",
       "      <td>творчество создание новое изобразительный иску...</td>\n",
       "      <td>отстать поезд современность получить знание но...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>универсальные компетенции  гибкие навыки soft ...</td>\n",
       "      <td>самореализация получить знания в новой области...</td>\n",
       "      <td>['универсальные', 'компетенции', '', 'гибкие',...</td>\n",
       "      <td>['самореализация', 'получить', 'знания', 'в', ...</td>\n",
       "      <td>универсальный компетенция  гибкий навык soft s...</td>\n",
       "      <td>самореализация получить знание новый область  ...</td>\n",
       "      <td>универсальный компетенция гибкий навык навык о...</td>\n",
       "      <td>самореализация получить знание новый область п...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>иностранные языки  гуманитарные знания и навык...</td>\n",
       "      <td>улучшенный образ жизни включиться в новый прое...</td>\n",
       "      <td>['иностранные', 'языки', '', 'гуманитарные', '...</td>\n",
       "      <td>['улучшенный', 'образ', 'жизни', 'включиться',...</td>\n",
       "      <td>иностранный язык  гуманитарный знание навык ин...</td>\n",
       "      <td>улучшить образ жизнь включиться новый проект д...</td>\n",
       "      <td>иностранный язык гуманитарный знание навык ино...</td>\n",
       "      <td>образ жизнь включиться новый проект деятельность</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>прикладные знания и навыки  ручной труд информ...</td>\n",
       "      <td>обновление устаревшей информации развить имеющ...</td>\n",
       "      <td>['прикладные', 'знания', 'и', 'навыки', '', 'р...</td>\n",
       "      <td>['обновление', 'устаревшей', 'информации', 'ра...</td>\n",
       "      <td>прикладной знание навык  ручной труд информаци...</td>\n",
       "      <td>обновление устаревший информация развить иметь...</td>\n",
       "      <td>прикладной знание навык ручной труд информация...</td>\n",
       "      <td>обновление устаревший информация развить знани...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>универсальные компетенции  гибкие навыки soft ...</td>\n",
       "      <td>повышение результативности труда получить знан...</td>\n",
       "      <td>['универсальные', 'компетенции', '', 'гибкие',...</td>\n",
       "      <td>['повышение', 'результативности', 'труда', 'по...</td>\n",
       "      <td>универсальный компетенция  гибкий навык soft s...</td>\n",
       "      <td>повышение результативность труд получить знани...</td>\n",
       "      <td>универсальный компетенция гибкий навык планиро...</td>\n",
       "      <td>повышение результативность труд получить знани...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   goal_id                               goal_domain_original  \\\n",
       "0       19  творчество и создание нового изобразительное и...   \n",
       "1       20  универсальные компетенции  гибкие навыки soft ...   \n",
       "2       21  иностранные языки  гуманитарные знания и навык...   \n",
       "3       22  прикладные знания и навыки  ручной труд информ...   \n",
       "4       23  универсальные компетенции  гибкие навыки soft ...   \n",
       "\n",
       "                             goal_name_type_original  \\\n",
       "0  не отстать от поезда современности получить зн...   \n",
       "1  самореализация получить знания в новой области...   \n",
       "2  улучшенный образ жизни включиться в новый прое...   \n",
       "3  обновление устаревшей информации развить имеющ...   \n",
       "4  повышение результативности труда получить знан...   \n",
       "\n",
       "                                     goal_domain_LoW  \\\n",
       "0  ['творчество', 'и', 'создание', 'нового', 'изо...   \n",
       "1  ['универсальные', 'компетенции', '', 'гибкие',...   \n",
       "2  ['иностранные', 'языки', '', 'гуманитарные', '...   \n",
       "3  ['прикладные', 'знания', 'и', 'навыки', '', 'р...   \n",
       "4  ['универсальные', 'компетенции', '', 'гибкие',...   \n",
       "\n",
       "                                  goal_name_type_LoW  \\\n",
       "0  ['не', 'отстать', 'от', 'поезда', 'современнос...   \n",
       "1  ['самореализация', 'получить', 'знания', 'в', ...   \n",
       "2  ['улучшенный', 'образ', 'жизни', 'включиться',...   \n",
       "3  ['обновление', 'устаревшей', 'информации', 'ра...   \n",
       "4  ['повышение', 'результативности', 'труда', 'по...   \n",
       "\n",
       "                                goal_domain_no_noise  \\\n",
       "0  творчество создание новое изобразительный иску...   \n",
       "1  универсальный компетенция  гибкий навык soft s...   \n",
       "2  иностранный язык  гуманитарный знание навык ин...   \n",
       "3  прикладной знание навык  ручной труд информаци...   \n",
       "4  универсальный компетенция  гибкий навык soft s...   \n",
       "\n",
       "                             goal_name_type_no_noise  \\\n",
       "0  отстать поезд современность получить знание но...   \n",
       "1  самореализация получить знание новый область  ...   \n",
       "2  улучшить образ жизнь включиться новый проект д...   \n",
       "3  обновление устаревший информация развить иметь...   \n",
       "4  повышение результативность труд получить знани...   \n",
       "\n",
       "                                goal_domain_mean_pos  \\\n",
       "0  творчество создание новое изобразительный иску...   \n",
       "1  универсальный компетенция гибкий навык навык о...   \n",
       "2  иностранный язык гуманитарный знание навык ино...   \n",
       "3  прикладной знание навык ручной труд информация...   \n",
       "4  универсальный компетенция гибкий навык планиро...   \n",
       "\n",
       "                             goal_name_type_mean_pos  remove  ...  \\\n",
       "0  отстать поезд современность получить знание но...       0  ...   \n",
       "1  самореализация получить знание новый область п...       0  ...   \n",
       "2   образ жизнь включиться новый проект деятельность       0  ...   \n",
       "3  обновление устаревший информация развить знани...       0  ...   \n",
       "4  повышение результативность труд получить знани...       0  ...   \n",
       "\n",
       "   label_attractor_hard_skill  label_attractor_soft_skill  \\\n",
       "0                           1                           1   \n",
       "1                           1                           0   \n",
       "2                           1                           1   \n",
       "3                           1                           0   \n",
       "4                           1                           0   \n",
       "\n",
       "   label_attractor_tool  label_attractor_community  \\\n",
       "0                     0                          1   \n",
       "1                     1                          0   \n",
       "2                     0                          0   \n",
       "3                     0                          0   \n",
       "4                     0                          0   \n",
       "\n",
       "   label_attractor_subjectivity  label_attractor_habits  \\\n",
       "0                             0                       1   \n",
       "1                             1                       0   \n",
       "2                             0                       0   \n",
       "3                             1                       1   \n",
       "4                             0                       0   \n",
       "\n",
       "   label_attractor_career  label_attractor_fixing  label_attractor_art  \\\n",
       "0                       1                       1                    0   \n",
       "1                       1                       0                    1   \n",
       "2                       0                       1                    0   \n",
       "3                       1                       1                    1   \n",
       "4                       0                       0                    1   \n",
       "\n",
       "   label_attractor_health  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goal_id', 'goal_domain_original', 'goal_name_type_original',\n",
       "       'goal_domain_LoW', 'goal_name_type_LoW', 'goal_domain_no_noise',\n",
       "       'goal_name_type_no_noise', 'goal_domain_mean_pos',\n",
       "       'goal_name_type_mean_pos', 'remove', 'are_first_steps_known',\n",
       "       'is_time_certain', 'is_certainly_imagined', 'are_obstackles_expected',\n",
       "       'topic_words', 'goal_words', 'topic_letters', 'goal_letters',\n",
       "       'topic_aver_word_len', 'goal_aver_word_len', 'goal_verbs_counter',\n",
       "       'goal_nouns_counter', 'goal_numr_counter', 'goal_adj_counter',\n",
       "       'goal_digit_counter', 'label_attractor_knowledge',\n",
       "       'label_attractor_hard_skill', 'label_attractor_soft_skill',\n",
       "       'label_attractor_tool', 'label_attractor_community',\n",
       "       'label_attractor_subjectivity', 'label_attractor_habits',\n",
       "       'label_attractor_career', 'label_attractor_fixing',\n",
       "       'label_attractor_art', 'label_attractor_health'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics[topics['remove'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.drop(columns=['remove'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_cols = ['label_attractor_knowledge',\n",
    "       'label_attractor_hard_skill', 'label_attractor_soft_skill',\n",
    "       'label_attractor_tool', 'label_attractor_community',\n",
    "       'label_attractor_subjectivity', 'label_attractor_habits',\n",
    "       'label_attractor_career', 'label_attractor_fixing',\n",
    "       'label_attractor_art', 'label_attractor_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in topic_cols:\n",
    "    topics_text_vectors = topics[['goal_domain_mean_pos', topic]]\n",
    "    topics_text_vectors.dropna(inplace=True)\n",
    "    text = topics_text_vectors['goal_domain_mean_pos']\n",
    "    y = topics_text_vectors[topic]\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X = tfidf.fit_transform(text)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    name = topic.split('_')[-1]\n",
    "    with open(f'../models/topics_domain/domain_{name}_vect_xgb.pkl', 'wb') as f:\n",
    "        pickle.dump(xgb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    vec_size = 100\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, vec_size, input_length=max_length))\n",
    "\n",
    "    model.add(Conv1D(32, 2, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 5s 369us/sample - loss: 0.3444 - accuracy: 0.8957 - val_loss: 0.4556 - val_accuracy: 0.8958\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 4s 323us/sample - loss: 0.3390 - accuracy: 0.8957 - val_loss: 0.4447 - val_accuracy: 0.8958\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.3370 - accuracy: 0.8957 - val_loss: 0.4681 - val_accuracy: 0.8958\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 4s 321us/sample - loss: 0.3374 - accuracy: 0.8957 - val_loss: 0.4444 - val_accuracy: 0.8958\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 4s 317us/sample - loss: 0.3361 - accuracy: 0.8957 - val_loss: 0.4498 - val_accuracy: 0.8958\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 4s 319us/sample - loss: 0.3362 - accuracy: 0.8957 - val_loss: 0.4287 - val_accuracy: 0.8958\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 5s 337us/sample - loss: 0.3362 - accuracy: 0.8957 - val_loss: 0.4198 - val_accuracy: 0.8958\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.3339 - accuracy: 0.8957 - val_loss: 0.4232 - val_accuracy: 0.8958\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 4s 323us/sample - loss: 0.3334 - accuracy: 0.8957 - val_loss: 0.4376 - val_accuracy: 0.8958\n",
      "Epoch 10/600\n",
      "13661/13661 [==============================] - 4s 319us/sample - loss: 0.3307 - accuracy: 0.8957 - val_loss: 0.4050 - val_accuracy: 0.8958\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 5s 343us/sample - loss: 0.3293 - accuracy: 0.8957 - val_loss: 0.4017 - val_accuracy: 0.8958\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 4s 325us/sample - loss: 0.3266 - accuracy: 0.8957 - val_loss: 0.4182 - val_accuracy: 0.8958\n",
      "Epoch 13/600\n",
      "13661/13661 [==============================] - 4s 321us/sample - loss: 0.3248 - accuracy: 0.8957 - val_loss: 0.4115 - val_accuracy: 0.8958\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 4s 322us/sample - loss: 0.3229 - accuracy: 0.8957 - val_loss: 0.4232 - val_accuracy: 0.8958\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.3215 - accuracy: 0.8957 - val_loss: 0.4210 - val_accuracy: 0.8958\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.3174 - accuracy: 0.8957 - val_loss: 0.4384 - val_accuracy: 0.8958\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.3171 - accuracy: 0.8957 - val_loss: 0.4288 - val_accuracy: 0.8958\n",
      "Epoch 18/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.3155 - accuracy: 0.8957 - val_loss: 0.4277 - val_accuracy: 0.8958\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 5s 346us/sample - loss: 0.3141 - accuracy: 0.8957 - val_loss: 0.4318 - val_accuracy: 0.8958\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 5s 351us/sample - loss: 0.3123 - accuracy: 0.8957 - val_loss: 0.4313 - val_accuracy: 0.8958\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 4s 317us/sample - loss: 0.3097 - accuracy: 0.8959 - val_loss: 0.4373 - val_accuracy: 0.8958\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 4s 326us/sample - loss: 0.3081 - accuracy: 0.8966 - val_loss: 0.4440 - val_accuracy: 0.8958\n",
      "Epoch 23/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.3068 - accuracy: 0.8963 - val_loss: 0.4601 - val_accuracy: 0.8934\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.3043 - accuracy: 0.8974 - val_loss: 0.4534 - val_accuracy: 0.8931\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 4s 325us/sample - loss: 0.3019 - accuracy: 0.8980 - val_loss: 0.4608 - val_accuracy: 0.8905\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 5s 333us/sample - loss: 0.3006 - accuracy: 0.8991 - val_loss: 0.4490 - val_accuracy: 0.8914\n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 5s 333us/sample - loss: 0.2968 - accuracy: 0.8995 - val_loss: 0.4616 - val_accuracy: 0.8885\n",
      "Epoch 28/600\n",
      "13661/13661 [==============================] - 5s 348us/sample - loss: 0.2969 - accuracy: 0.9007 - val_loss: 0.4577 - val_accuracy: 0.8896\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 376us/sample - loss: 0.2911 - accuracy: 0.9031 - val_loss: 0.4618 - val_accuracy: 0.8870\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 5s 352us/sample - loss: 0.2935 - accuracy: 0.9023 - val_loss: 0.4553 - val_accuracy: 0.8914\n",
      "Epoch 31/600\n",
      "13661/13661 [==============================] - 4s 321us/sample - loss: 0.2875 - accuracy: 0.9032 - val_loss: 0.5174 - val_accuracy: 0.8879\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 5s 348us/sample - loss: 0.2882 - accuracy: 0.9043 - val_loss: 0.4957 - val_accuracy: 0.8867\n",
      "Epoch 33/600\n",
      "13661/13661 [==============================] - 4s 323us/sample - loss: 0.2852 - accuracy: 0.9056 - val_loss: 0.5223 - val_accuracy: 0.8873\n",
      "Epoch 34/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.2840 - accuracy: 0.9050 - val_loss: 0.4995 - val_accuracy: 0.8902\n",
      "Epoch 35/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.2838 - accuracy: 0.9062 - val_loss: 0.5040 - val_accuracy: 0.8809\n",
      "Epoch 36/600\n",
      "13661/13661 [==============================] - 4s 317us/sample - loss: 0.2839 - accuracy: 0.9057 - val_loss: 0.5066 - val_accuracy: 0.8847\n",
      "Epoch 00036: early stopping\n",
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 5s 398us/sample - loss: 0.4943 - accuracy: 0.8057 - val_loss: 0.5414 - val_accuracy: 0.8147\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.4817 - accuracy: 0.8147 - val_loss: 0.5473 - val_accuracy: 0.8147\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 4s 325us/sample - loss: 0.4817 - accuracy: 0.8147 - val_loss: 0.5488 - val_accuracy: 0.8147\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.4810 - accuracy: 0.8147 - val_loss: 0.5439 - val_accuracy: 0.8147\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 4s 326us/sample - loss: 0.4818 - accuracy: 0.8147 - val_loss: 0.5471 - val_accuracy: 0.8147\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.4806 - accuracy: 0.8147 - val_loss: 0.5344 - val_accuracy: 0.8147\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 4s 325us/sample - loss: 0.4815 - accuracy: 0.8147 - val_loss: 0.5368 - val_accuracy: 0.8147\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 4s 310us/sample - loss: 0.4807 - accuracy: 0.8147 - val_loss: 0.5321 - val_accuracy: 0.8147\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 4s 311us/sample - loss: 0.4805 - accuracy: 0.8147 - val_loss: 0.5238 - val_accuracy: 0.8147\n",
      "Epoch 10/600\n",
      "13661/13661 [==============================] - 4s 307us/sample - loss: 0.4808 - accuracy: 0.8147 - val_loss: 0.5349 - val_accuracy: 0.8147\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 4s 315us/sample - loss: 0.4805 - accuracy: 0.8147 - val_loss: 0.5263 - val_accuracy: 0.8147\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 4s 314us/sample - loss: 0.4807 - accuracy: 0.8147 - val_loss: 0.5278 - val_accuracy: 0.8147\n",
      "Epoch 13/600\n",
      "13661/13661 [==============================] - 4s 308us/sample - loss: 0.4805 - accuracy: 0.8147 - val_loss: 0.5324 - val_accuracy: 0.8147\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 4s 307us/sample - loss: 0.4806 - accuracy: 0.8147 - val_loss: 0.5190 - val_accuracy: 0.8147\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 4s 299us/sample - loss: 0.4799 - accuracy: 0.8147 - val_loss: 0.5211 - val_accuracy: 0.8147\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 4s 315us/sample - loss: 0.4803 - accuracy: 0.8147 - val_loss: 0.5176 - val_accuracy: 0.8147\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 4s 320us/sample - loss: 0.4800 - accuracy: 0.8147 - val_loss: 0.5164 - val_accuracy: 0.8147\n",
      "Epoch 18/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.4795 - accuracy: 0.8147 - val_loss: 0.5061 - val_accuracy: 0.8147\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 4s 303us/sample - loss: 0.4801 - accuracy: 0.8147 - val_loss: 0.5122 - val_accuracy: 0.8147\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 4s 315us/sample - loss: 0.4790 - accuracy: 0.8147 - val_loss: 0.5143 - val_accuracy: 0.8147\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 4s 324us/sample - loss: 0.4777 - accuracy: 0.8147 - val_loss: 0.5097 - val_accuracy: 0.8147\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 4s 308us/sample - loss: 0.4753 - accuracy: 0.8147 - val_loss: 0.5098 - val_accuracy: 0.8147\n",
      "Epoch 23/600\n",
      "13661/13661 [==============================] - 4s 323us/sample - loss: 0.4716 - accuracy: 0.8147 - val_loss: 0.5178 - val_accuracy: 0.8147\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 4s 318us/sample - loss: 0.4676 - accuracy: 0.8147 - val_loss: 0.5139 - val_accuracy: 0.8147\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 4s 313us/sample - loss: 0.4612 - accuracy: 0.8150 - val_loss: 0.5253 - val_accuracy: 0.8106\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 5s 363us/sample - loss: 0.4521 - accuracy: 0.8194 - val_loss: 0.5296 - val_accuracy: 0.8088\n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.4441 - accuracy: 0.8229 - val_loss: 0.5371 - val_accuracy: 0.8053\n",
      "Epoch 28/600\n",
      "13661/13661 [==============================] - 5s 369us/sample - loss: 0.4385 - accuracy: 0.8256 - val_loss: 0.5501 - val_accuracy: 0.8050\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.4327 - accuracy: 0.8290 - val_loss: 0.5603 - val_accuracy: 0.8047\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 5s 346us/sample - loss: 0.4260 - accuracy: 0.8324 - val_loss: 0.5743 - val_accuracy: 0.8077\n",
      "Epoch 31/600\n",
      "13661/13661 [==============================] - 4s 326us/sample - loss: 0.4226 - accuracy: 0.8334 - val_loss: 0.5839 - val_accuracy: 0.8018\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.4179 - accuracy: 0.8343 - val_loss: 0.5873 - val_accuracy: 0.8033\n",
      "Epoch 33/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.4145 - accuracy: 0.8364 - val_loss: 0.6026 - val_accuracy: 0.8024\n",
      "Epoch 34/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.4114 - accuracy: 0.8382 - val_loss: 0.6298 - val_accuracy: 0.8015\n",
      "Epoch 35/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.4113 - accuracy: 0.8389 - val_loss: 0.6101 - val_accuracy: 0.8006\n",
      "Epoch 36/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.4088 - accuracy: 0.8383 - val_loss: 0.6370 - val_accuracy: 0.7954\n",
      "Epoch 37/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.4089 - accuracy: 0.8390 - val_loss: 0.6464 - val_accuracy: 0.8004\n",
      "Epoch 38/600\n",
      "13661/13661 [==============================] - 5s 333us/sample - loss: 0.4054 - accuracy: 0.8409 - val_loss: 0.6617 - val_accuracy: 0.8006\n",
      "Epoch 39/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.4052 - accuracy: 0.8401 - val_loss: 0.6543 - val_accuracy: 0.7995\n",
      "Epoch 40/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.4030 - accuracy: 0.8414 - val_loss: 0.6874 - val_accuracy: 0.7986\n",
      "Epoch 41/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.4040 - accuracy: 0.8400 - val_loss: 0.6824 - val_accuracy: 0.7930\n",
      "Epoch 42/600\n",
      "13661/13661 [==============================] - 5s 375us/sample - loss: 0.4031 - accuracy: 0.8419 - val_loss: 0.6851 - val_accuracy: 0.8006\n",
      "Epoch 43/600\n",
      "13661/13661 [==============================] - 5s 340us/sample - loss: 0.4038 - accuracy: 0.8405 - val_loss: 0.6569 - val_accuracy: 0.8018\n",
      "Epoch 00043: early stopping\n",
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 5s 391us/sample - loss: 0.5784 - accuracy: 0.7397 - val_loss: 0.6134 - val_accuracy: 0.7398\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.5756 - accuracy: 0.7397 - val_loss: 0.6222 - val_accuracy: 0.7398\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 4s 312us/sample - loss: 0.5761 - accuracy: 0.7397 - val_loss: 0.6106 - val_accuracy: 0.7398\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 4s 313us/sample - loss: 0.5752 - accuracy: 0.7397 - val_loss: 0.6034 - val_accuracy: 0.7398\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 4s 307us/sample - loss: 0.5744 - accuracy: 0.7397 - val_loss: 0.5990 - val_accuracy: 0.7398\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 4s 324us/sample - loss: 0.5743 - accuracy: 0.7397 - val_loss: 0.6084 - val_accuracy: 0.7398\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 4s 314us/sample - loss: 0.5753 - accuracy: 0.7397 - val_loss: 0.6043 - val_accuracy: 0.7398\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 5s 391us/sample - loss: 0.5739 - accuracy: 0.7397 - val_loss: 0.5950 - val_accuracy: 0.7398\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.5733 - accuracy: 0.7397 - val_loss: 0.5936 - val_accuracy: 0.7398\n",
      "Epoch 10/600\n",
      "13661/13661 [==============================] - 4s 310us/sample - loss: 0.5732 - accuracy: 0.7397 - val_loss: 0.5932 - val_accuracy: 0.7398\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 4s 314us/sample - loss: 0.5711 - accuracy: 0.7397 - val_loss: 0.5968 - val_accuracy: 0.7398\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 4s 313us/sample - loss: 0.5683 - accuracy: 0.7397 - val_loss: 0.5928 - val_accuracy: 0.7398\n",
      "Epoch 13/600\n",
      "13661/13661 [==============================] - 4s 320us/sample - loss: 0.5646 - accuracy: 0.7397 - val_loss: 0.5960 - val_accuracy: 0.7398\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 4s 322us/sample - loss: 0.5595 - accuracy: 0.7397 - val_loss: 0.6022 - val_accuracy: 0.7398\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 4s 317us/sample - loss: 0.5547 - accuracy: 0.7397 - val_loss: 0.6038 - val_accuracy: 0.7398\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 4s 326us/sample - loss: 0.5509 - accuracy: 0.7397 - val_loss: 0.6102 - val_accuracy: 0.7398\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 4s 304us/sample - loss: 0.5456 - accuracy: 0.7397 - val_loss: 0.6266 - val_accuracy: 0.7398\n",
      "Epoch 18/600\n",
      "13661/13661 [==============================] - 4s 315us/sample - loss: 0.5438 - accuracy: 0.7397 - val_loss: 0.6300 - val_accuracy: 0.7398\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 4s 302us/sample - loss: 0.5402 - accuracy: 0.7397 - val_loss: 0.6421 - val_accuracy: 0.7398\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.5383 - accuracy: 0.7397 - val_loss: 0.6495 - val_accuracy: 0.7398\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 4s 308us/sample - loss: 0.5373 - accuracy: 0.7397 - val_loss: 0.6569 - val_accuracy: 0.7398\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 4s 315us/sample - loss: 0.5337 - accuracy: 0.7399 - val_loss: 0.6744 - val_accuracy: 0.7398\n",
      "Epoch 23/600\n",
      "13661/13661 [==============================] - 4s 321us/sample - loss: 0.5332 - accuracy: 0.7398 - val_loss: 0.6860 - val_accuracy: 0.7398\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 4s 314us/sample - loss: 0.5267 - accuracy: 0.7443 - val_loss: 0.6660 - val_accuracy: 0.7351\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 4s 315us/sample - loss: 0.5205 - accuracy: 0.7518 - val_loss: 0.7072 - val_accuracy: 0.7263\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 4s 320us/sample - loss: 0.5141 - accuracy: 0.7573 - val_loss: 0.7029 - val_accuracy: 0.7295\n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.5082 - accuracy: 0.7607 - val_loss: 0.7352 - val_accuracy: 0.7272\n",
      "Epoch 28/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.5034 - accuracy: 0.7652 - val_loss: 0.7344 - val_accuracy: 0.7242\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 337us/sample - loss: 0.4994 - accuracy: 0.7680 - val_loss: 0.7608 - val_accuracy: 0.7257\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.4967 - accuracy: 0.7703 - val_loss: 0.7617 - val_accuracy: 0.7289\n",
      "Epoch 31/600\n",
      "13661/13661 [==============================] - 4s 326us/sample - loss: 0.4928 - accuracy: 0.7716 - val_loss: 0.7771 - val_accuracy: 0.7234\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.4896 - accuracy: 0.7725 - val_loss: 0.8402 - val_accuracy: 0.7251\n",
      "Epoch 33/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.4892 - accuracy: 0.7743 - val_loss: 0.8214 - val_accuracy: 0.7263\n",
      "Epoch 34/600\n",
      "13661/13661 [==============================] - 4s 319us/sample - loss: 0.4866 - accuracy: 0.7755 - val_loss: 0.8389 - val_accuracy: 0.7254\n",
      "Epoch 35/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.4866 - accuracy: 0.7765 - val_loss: 0.8083 - val_accuracy: 0.7263\n",
      "Epoch 36/600\n",
      "13661/13661 [==============================] - 4s 320us/sample - loss: 0.4855 - accuracy: 0.7763 - val_loss: 0.8105 - val_accuracy: 0.7242\n",
      "Epoch 37/600\n",
      "13661/13661 [==============================] - 4s 307us/sample - loss: 0.4832 - accuracy: 0.7765 - val_loss: 0.8103 - val_accuracy: 0.7257\n",
      "Epoch 00037: early stopping\n",
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 5s 379us/sample - loss: 0.3088 - accuracy: 0.9087 - val_loss: 0.3957 - val_accuracy: 0.9148\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.2942 - accuracy: 0.9148 - val_loss: 0.3887 - val_accuracy: 0.9148\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 5s 337us/sample - loss: 0.2932 - accuracy: 0.9148 - val_loss: 0.4222 - val_accuracy: 0.9148\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.2943 - accuracy: 0.9148 - val_loss: 0.4120 - val_accuracy: 0.9148\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.2929 - accuracy: 0.9148 - val_loss: 0.4088 - val_accuracy: 0.9148\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.2949 - accuracy: 0.9148 - val_loss: 0.3853 - val_accuracy: 0.9148\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 4s 326us/sample - loss: 0.2928 - accuracy: 0.9148 - val_loss: 0.3680 - val_accuracy: 0.9148\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 5s 338us/sample - loss: 0.2933 - accuracy: 0.9148 - val_loss: 0.3640 - val_accuracy: 0.9148\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.2938 - accuracy: 0.9148 - val_loss: 0.3863 - val_accuracy: 0.9148\n",
      "Epoch 10/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.2919 - accuracy: 0.9148 - val_loss: 0.3760 - val_accuracy: 0.9148\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 4s 325us/sample - loss: 0.2926 - accuracy: 0.9148 - val_loss: 0.3761 - val_accuracy: 0.9148\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.2923 - accuracy: 0.9148 - val_loss: 0.3639 - val_accuracy: 0.9148\n",
      "Epoch 13/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.2941 - accuracy: 0.9148 - val_loss: 0.3636 - val_accuracy: 0.9148\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.2924 - accuracy: 0.9148 - val_loss: 0.3465 - val_accuracy: 0.9148\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.2917 - accuracy: 0.9148 - val_loss: 0.3389 - val_accuracy: 0.9148\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.2918 - accuracy: 0.9148 - val_loss: 0.3585 - val_accuracy: 0.9148\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.2915 - accuracy: 0.9148 - val_loss: 0.3611 - val_accuracy: 0.9148\n",
      "Epoch 18/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.2912 - accuracy: 0.9148 - val_loss: 0.3538 - val_accuracy: 0.9148\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.2912 - accuracy: 0.9148 - val_loss: 0.3512 - val_accuracy: 0.9148\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 4s 314us/sample - loss: 0.2909 - accuracy: 0.9148 - val_loss: 0.3565 - val_accuracy: 0.9148\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 4s 322us/sample - loss: 0.2904 - accuracy: 0.9148 - val_loss: 0.3430 - val_accuracy: 0.9148\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 4s 311us/sample - loss: 0.2896 - accuracy: 0.9148 - val_loss: 0.3318 - val_accuracy: 0.9148\n",
      "Epoch 23/600\n",
      "13661/13661 [==============================] - 4s 323us/sample - loss: 0.2894 - accuracy: 0.9148 - val_loss: 0.3428 - val_accuracy: 0.9148\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 4s 315us/sample - loss: 0.2887 - accuracy: 0.9148 - val_loss: 0.3471 - val_accuracy: 0.9148\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 4s 324us/sample - loss: 0.2837 - accuracy: 0.9147 - val_loss: 0.3319 - val_accuracy: 0.9142\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 5s 364us/sample - loss: 0.2818 - accuracy: 0.9152 - val_loss: 0.3509 - val_accuracy: 0.9136\n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 5s 368us/sample - loss: 0.2768 - accuracy: 0.9160 - val_loss: 0.3416 - val_accuracy: 0.9110\n",
      "Epoch 28/600\n",
      "13661/13661 [==============================] - 5s 367us/sample - loss: 0.2731 - accuracy: 0.9168 - val_loss: 0.3434 - val_accuracy: 0.9110\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 367us/sample - loss: 0.2684 - accuracy: 0.9178 - val_loss: 0.3520 - val_accuracy: 0.9095\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 5s 369us/sample - loss: 0.2632 - accuracy: 0.9196 - val_loss: 0.3539 - val_accuracy: 0.9093\n",
      "Epoch 31/600\n",
      "13661/13661 [==============================] - 5s 366us/sample - loss: 0.2598 - accuracy: 0.9208 - val_loss: 0.3528 - val_accuracy: 0.9104\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 5s 364us/sample - loss: 0.2574 - accuracy: 0.9214 - val_loss: 0.3723 - val_accuracy: 0.9078\n",
      "Epoch 33/600\n",
      "13661/13661 [==============================] - 5s 364us/sample - loss: 0.2555 - accuracy: 0.9229 - val_loss: 0.3724 - val_accuracy: 0.9081\n",
      "Epoch 34/600\n",
      "13661/13661 [==============================] - 5s 368us/sample - loss: 0.2513 - accuracy: 0.9237 - val_loss: 0.3783 - val_accuracy: 0.9098\n",
      "Epoch 35/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.2496 - accuracy: 0.9236 - val_loss: 0.3926 - val_accuracy: 0.9063\n",
      "Epoch 36/600\n",
      "13661/13661 [==============================] - 4s 324us/sample - loss: 0.2479 - accuracy: 0.9246 - val_loss: 0.3826 - val_accuracy: 0.9052\n",
      "Epoch 37/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.2457 - accuracy: 0.9254 - val_loss: 0.4008 - val_accuracy: 0.9078\n",
      "Epoch 38/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.2439 - accuracy: 0.9260 - val_loss: 0.4132 - val_accuracy: 0.9011\n",
      "Epoch 39/600\n",
      "13661/13661 [==============================] - 5s 368us/sample - loss: 0.2425 - accuracy: 0.9261 - val_loss: 0.4284 - val_accuracy: 0.9049\n",
      "Epoch 40/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.2427 - accuracy: 0.9253 - val_loss: 0.4318 - val_accuracy: 0.9081\n",
      "Epoch 41/600\n",
      "13661/13661 [==============================] - 5s 369us/sample - loss: 0.2422 - accuracy: 0.9258 - val_loss: 0.4179 - val_accuracy: 0.9060\n",
      "Epoch 42/600\n",
      "13661/13661 [==============================] - 5s 360us/sample - loss: 0.2428 - accuracy: 0.9262 - val_loss: 0.4225 - val_accuracy: 0.9019\n",
      "Epoch 43/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.2418 - accuracy: 0.9258 - val_loss: 0.4375 - val_accuracy: 0.9066\n",
      "Epoch 44/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.2400 - accuracy: 0.9264 - val_loss: 0.4381 - val_accuracy: 0.9040\n",
      "Epoch 45/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.2404 - accuracy: 0.9267 - val_loss: 0.4423 - val_accuracy: 0.9028\n",
      "Epoch 46/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.2380 - accuracy: 0.9276 - val_loss: 0.4603 - val_accuracy: 0.9019\n",
      "Epoch 47/600\n",
      "13661/13661 [==============================] - 5s 344us/sample - loss: 0.2400 - accuracy: 0.9265 - val_loss: 0.4448 - val_accuracy: 0.9049\n",
      "Epoch 00047: early stopping\n",
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 6s 427us/sample - loss: 0.5062 - accuracy: 0.8028 - val_loss: 0.5426 - val_accuracy: 0.8033\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 5s 365us/sample - loss: 0.4989 - accuracy: 0.8033 - val_loss: 0.5497 - val_accuracy: 0.8033\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 5s 363us/sample - loss: 0.4975 - accuracy: 0.8033 - val_loss: 0.5556 - val_accuracy: 0.8033\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.4980 - accuracy: 0.8033 - val_loss: 0.5478 - val_accuracy: 0.8033\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.4981 - accuracy: 0.8033 - val_loss: 0.5548 - val_accuracy: 0.8033\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.4982 - accuracy: 0.8033 - val_loss: 0.5467 - val_accuracy: 0.8033\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 5s 340us/sample - loss: 0.4968 - accuracy: 0.8033 - val_loss: 0.5542 - val_accuracy: 0.8033\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 5s 344us/sample - loss: 0.4963 - accuracy: 0.8033 - val_loss: 0.5517 - val_accuracy: 0.8033\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.4968 - accuracy: 0.8033 - val_loss: 0.5538 - val_accuracy: 0.8033\n",
      "Epoch 10/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.4963 - accuracy: 0.8033 - val_loss: 0.5478 - val_accuracy: 0.8033\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.4964 - accuracy: 0.8033 - val_loss: 0.5439 - val_accuracy: 0.8033\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 5s 333us/sample - loss: 0.4949 - accuracy: 0.8033 - val_loss: 0.5242 - val_accuracy: 0.8033\n",
      "Epoch 13/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.4951 - accuracy: 0.8033 - val_loss: 0.5403 - val_accuracy: 0.8033\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.4932 - accuracy: 0.8033 - val_loss: 0.5440 - val_accuracy: 0.8033\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 4s 326us/sample - loss: 0.4919 - accuracy: 0.8033 - val_loss: 0.5376 - val_accuracy: 0.8033\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.4901 - accuracy: 0.8033 - val_loss: 0.5362 - val_accuracy: 0.8033\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.4870 - accuracy: 0.8033 - val_loss: 0.5421 - val_accuracy: 0.8033\n",
      "Epoch 18/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.4836 - accuracy: 0.8032 - val_loss: 0.5339 - val_accuracy: 0.8033\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 5s 333us/sample - loss: 0.4803 - accuracy: 0.8032 - val_loss: 0.5480 - val_accuracy: 0.8033\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.4764 - accuracy: 0.8030 - val_loss: 0.5420 - val_accuracy: 0.8033\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 5s 344us/sample - loss: 0.4698 - accuracy: 0.8043 - val_loss: 0.5423 - val_accuracy: 0.8033\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 5s 347us/sample - loss: 0.4621 - accuracy: 0.8067 - val_loss: 0.5584 - val_accuracy: 0.8006\n",
      "Epoch 23/600\n",
      "13661/13661 [==============================] - 5s 359us/sample - loss: 0.4543 - accuracy: 0.8140 - val_loss: 0.5592 - val_accuracy: 0.7957\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 5s 356us/sample - loss: 0.4430 - accuracy: 0.8204 - val_loss: 0.5660 - val_accuracy: 0.7922\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 5s 352us/sample - loss: 0.4337 - accuracy: 0.8248 - val_loss: 0.5893 - val_accuracy: 0.7919\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 5s 353us/sample - loss: 0.4295 - accuracy: 0.8256 - val_loss: 0.5999 - val_accuracy: 0.7901\n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 5s 357us/sample - loss: 0.4275 - accuracy: 0.8267 - val_loss: 0.6047 - val_accuracy: 0.7895\n",
      "Epoch 28/600\n",
      "13661/13661 [==============================] - 5s 345us/sample - loss: 0.4260 - accuracy: 0.8276 - val_loss: 0.6192 - val_accuracy: 0.7910\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.4228 - accuracy: 0.8284 - val_loss: 0.6162 - val_accuracy: 0.7878\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 4s 325us/sample - loss: 0.4186 - accuracy: 0.8311 - val_loss: 0.6313 - val_accuracy: 0.7866\n",
      "Epoch 31/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.4175 - accuracy: 0.8302 - val_loss: 0.6428 - val_accuracy: 0.7875\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.4172 - accuracy: 0.8305 - val_loss: 0.6328 - val_accuracy: 0.7901\n",
      "Epoch 33/600\n",
      "13661/13661 [==============================] - 5s 329us/sample - loss: 0.4146 - accuracy: 0.8310 - val_loss: 0.6353 - val_accuracy: 0.7898\n",
      "Epoch 34/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.4123 - accuracy: 0.8319 - val_loss: 0.6807 - val_accuracy: 0.7872\n",
      "Epoch 35/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.4123 - accuracy: 0.8319 - val_loss: 0.6567 - val_accuracy: 0.7907\n",
      "Epoch 36/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.4107 - accuracy: 0.8335 - val_loss: 0.6833 - val_accuracy: 0.7854\n",
      "Epoch 37/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.4119 - accuracy: 0.8327 - val_loss: 0.6457 - val_accuracy: 0.7901\n",
      "Epoch 00037: early stopping\n",
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 5s 396us/sample - loss: 0.6558 - accuracy: 0.6375 - val_loss: 0.6694 - val_accuracy: 0.6417\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 5s 362us/sample - loss: 0.6535 - accuracy: 0.6416 - val_loss: 0.6660 - val_accuracy: 0.6417\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 5s 380us/sample - loss: 0.6535 - accuracy: 0.6415 - val_loss: 0.6625 - val_accuracy: 0.6417\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 5s 375us/sample - loss: 0.6530 - accuracy: 0.6416 - val_loss: 0.6618 - val_accuracy: 0.6417\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 5s 349us/sample - loss: 0.6532 - accuracy: 0.6416 - val_loss: 0.6615 - val_accuracy: 0.6417\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.6528 - accuracy: 0.6416 - val_loss: 0.6609 - val_accuracy: 0.6417\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.6530 - accuracy: 0.6415 - val_loss: 0.6586 - val_accuracy: 0.6417\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.6525 - accuracy: 0.6416 - val_loss: 0.6583 - val_accuracy: 0.6417\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 5s 346us/sample - loss: 0.6518 - accuracy: 0.6415 - val_loss: 0.6583 - val_accuracy: 0.6417\n",
      "Epoch 10/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.6504 - accuracy: 0.6411 - val_loss: 0.6567 - val_accuracy: 0.6417\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.6475 - accuracy: 0.6418 - val_loss: 0.6605 - val_accuracy: 0.6414\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 5s 346us/sample - loss: 0.6434 - accuracy: 0.6422 - val_loss: 0.6600 - val_accuracy: 0.6393\n",
      "Epoch 13/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.6359 - accuracy: 0.6494 - val_loss: 0.6676 - val_accuracy: 0.6329\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 5s 348us/sample - loss: 0.6273 - accuracy: 0.6567 - val_loss: 0.6731 - val_accuracy: 0.6332\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.6152 - accuracy: 0.6645 - val_loss: 0.6813 - val_accuracy: 0.6303\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.6058 - accuracy: 0.6744 - val_loss: 0.6952 - val_accuracy: 0.6282\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.5939 - accuracy: 0.6792 - val_loss: 0.7056 - val_accuracy: 0.6311\n",
      "Epoch 18/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.5850 - accuracy: 0.6832 - val_loss: 0.7193 - val_accuracy: 0.6314\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 5s 333us/sample - loss: 0.5774 - accuracy: 0.6884 - val_loss: 0.7432 - val_accuracy: 0.6303\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.5707 - accuracy: 0.6900 - val_loss: 0.7604 - val_accuracy: 0.6314\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 5s 340us/sample - loss: 0.5671 - accuracy: 0.6915 - val_loss: 0.7664 - val_accuracy: 0.6329\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.5642 - accuracy: 0.6928 - val_loss: 0.7741 - val_accuracy: 0.6326\n",
      "Epoch 23/600\n",
      "13661/13661 [==============================] - 5s 363us/sample - loss: 0.5621 - accuracy: 0.6943 - val_loss: 0.7985 - val_accuracy: 0.6326\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 5s 379us/sample - loss: 0.5570 - accuracy: 0.6972 - val_loss: 0.8317 - val_accuracy: 0.6335\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 5s 375us/sample - loss: 0.5547 - accuracy: 0.6983 - val_loss: 0.8393 - val_accuracy: 0.6311\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 5s 378us/sample - loss: 0.5553 - accuracy: 0.6989 - val_loss: 0.8403 - val_accuracy: 0.6311\n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 5s 378us/sample - loss: 0.5520 - accuracy: 0.7000 - val_loss: 0.8844 - val_accuracy: 0.6276\n",
      "Epoch 28/600\n",
      "13661/13661 [==============================] - 5s 380us/sample - loss: 0.5498 - accuracy: 0.7015 - val_loss: 0.9016 - val_accuracy: 0.6270\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 378us/sample - loss: 0.5483 - accuracy: 0.7038 - val_loss: 0.9280 - val_accuracy: 0.6285\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 5s 360us/sample - loss: 0.5463 - accuracy: 0.7033 - val_loss: 0.9256 - val_accuracy: 0.6300\n",
      "Epoch 31/600\n",
      "13661/13661 [==============================] - 5s 377us/sample - loss: 0.5446 - accuracy: 0.7043 - val_loss: 0.9855 - val_accuracy: 0.6276\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 5s 370us/sample - loss: 0.5449 - accuracy: 0.7054 - val_loss: 0.9770 - val_accuracy: 0.6288\n",
      "Epoch 33/600\n",
      "13661/13661 [==============================] - 5s 345us/sample - loss: 0.5433 - accuracy: 0.7046 - val_loss: 1.0179 - val_accuracy: 0.6256\n",
      "Epoch 34/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.5419 - accuracy: 0.7051 - val_loss: 0.9857 - val_accuracy: 0.6259\n",
      "Epoch 35/600\n",
      "13661/13661 [==============================] - 5s 344us/sample - loss: 0.5393 - accuracy: 0.7069 - val_loss: 1.0381 - val_accuracy: 0.6265\n",
      "Epoch 00035: early stopping\n",
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 5s 400us/sample - loss: 0.3739 - accuracy: 0.8802 - val_loss: 0.4565 - val_accuracy: 0.8861\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 5s 347us/sample - loss: 0.3571 - accuracy: 0.8860 - val_loss: 0.4467 - val_accuracy: 0.8861\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.3575 - accuracy: 0.8860 - val_loss: 0.4574 - val_accuracy: 0.8861\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 5s 358us/sample - loss: 0.3566 - accuracy: 0.8860 - val_loss: 0.4484 - val_accuracy: 0.8861\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 5s 369us/sample - loss: 0.3575 - accuracy: 0.8860 - val_loss: 0.4488 - val_accuracy: 0.8861\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 5s 385us/sample - loss: 0.3568 - accuracy: 0.8860 - val_loss: 0.4217 - val_accuracy: 0.8861\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 5s 390us/sample - loss: 0.3565 - accuracy: 0.8860 - val_loss: 0.4159 - val_accuracy: 0.8861\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 6s 423us/sample - loss: 0.3560 - accuracy: 0.8860 - val_loss: 0.4244 - val_accuracy: 0.8861\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 5s 350us/sample - loss: 0.3566 - accuracy: 0.8860 - val_loss: 0.4369 - val_accuracy: 0.8861\n",
      "Epoch 10/600\n",
      "13661/13661 [==============================] - 5s 354us/sample - loss: 0.3567 - accuracy: 0.8860 - val_loss: 0.4152 - val_accuracy: 0.8861\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 5s 347us/sample - loss: 0.3555 - accuracy: 0.8860 - val_loss: 0.4167 - val_accuracy: 0.8861\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 5s 345us/sample - loss: 0.3549 - accuracy: 0.8860 - val_loss: 0.4099 - val_accuracy: 0.8861\n",
      "Epoch 13/600\n",
      "13661/13661 [==============================] - 5s 337us/sample - loss: 0.3539 - accuracy: 0.8860 - val_loss: 0.4056 - val_accuracy: 0.8861\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.3539 - accuracy: 0.8860 - val_loss: 0.4115 - val_accuracy: 0.8861\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 5s 349us/sample - loss: 0.3517 - accuracy: 0.8860 - val_loss: 0.4207 - val_accuracy: 0.8861\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 5s 347us/sample - loss: 0.3482 - accuracy: 0.8860 - val_loss: 0.4231 - val_accuracy: 0.8861oss: 0.3457 - ac\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 5s 346us/sample - loss: 0.3473 - accuracy: 0.8860 - val_loss: 0.4011 - val_accuracy: 0.8861\n",
      "Epoch 18/600\n",
      "13661/13661 [==============================] - 5s 350us/sample - loss: 0.3445 - accuracy: 0.8860 - val_loss: 0.4153 - val_accuracy: 0.8861\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 5s 349us/sample - loss: 0.3440 - accuracy: 0.8860 - val_loss: 0.4240 - val_accuracy: 0.8861\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 5s 350us/sample - loss: 0.3423 - accuracy: 0.8860 - val_loss: 0.4318 - val_accuracy: 0.8861\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 5s 355us/sample - loss: 0.3405 - accuracy: 0.8860 - val_loss: 0.4096 - val_accuracy: 0.8861\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 5s 359us/sample - loss: 0.3387 - accuracy: 0.8860 - val_loss: 0.4221 - val_accuracy: 0.8861\n",
      "Epoch 23/600\n",
      "13661/13661 [==============================] - 5s 360us/sample - loss: 0.3370 - accuracy: 0.8862 - val_loss: 0.4372 - val_accuracy: 0.8861\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 5s 353us/sample - loss: 0.3351 - accuracy: 0.8865 - val_loss: 0.4434 - val_accuracy: 0.8861\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 5s 350us/sample - loss: 0.3320 - accuracy: 0.8863 - val_loss: 0.4383 - val_accuracy: 0.8858\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.3310 - accuracy: 0.8859 - val_loss: 0.4508 - val_accuracy: 0.8852\n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.3281 - accuracy: 0.8876 - val_loss: 0.4505 - val_accuracy: 0.8832\n",
      "Epoch 28/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.3222 - accuracy: 0.8900 - val_loss: 0.4651 - val_accuracy: 0.8797\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 338us/sample - loss: 0.3192 - accuracy: 0.8911 - val_loss: 0.4698 - val_accuracy: 0.8779\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.3149 - accuracy: 0.8927 - val_loss: 0.4921 - val_accuracy: 0.8730\n",
      "Epoch 31/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13661/13661 [==============================] - 5s 340us/sample - loss: 0.3140 - accuracy: 0.8938 - val_loss: 0.4918 - val_accuracy: 0.8753\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 5s 344us/sample - loss: 0.3106 - accuracy: 0.8952 - val_loss: 0.4893 - val_accuracy: 0.8738\n",
      "Epoch 33/600\n",
      "13661/13661 [==============================] - 5s 346us/sample - loss: 0.3095 - accuracy: 0.8952 - val_loss: 0.4944 - val_accuracy: 0.8730\n",
      "Epoch 34/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.3065 - accuracy: 0.8976 - val_loss: 0.4962 - val_accuracy: 0.8724\n",
      "Epoch 35/600\n",
      "13661/13661 [==============================] - 5s 354us/sample - loss: 0.3061 - accuracy: 0.8980 - val_loss: 0.4858 - val_accuracy: 0.8721\n",
      "Epoch 36/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.3041 - accuracy: 0.8986 - val_loss: 0.4968 - val_accuracy: 0.8715\n",
      "Epoch 37/600\n",
      "13661/13661 [==============================] - 5s 338us/sample - loss: 0.3029 - accuracy: 0.8991 - val_loss: 0.4988 - val_accuracy: 0.8718\n",
      "Epoch 38/600\n",
      "13661/13661 [==============================] - 5s 370us/sample - loss: 0.3023 - accuracy: 0.8988 - val_loss: 0.5112 - val_accuracy: 0.8718\n",
      "Epoch 39/600\n",
      "13661/13661 [==============================] - 5s 371us/sample - loss: 0.2975 - accuracy: 0.9016 - val_loss: 0.5300 - val_accuracy: 0.8709\n",
      "Epoch 40/600\n",
      "13661/13661 [==============================] - 5s 385us/sample - loss: 0.2997 - accuracy: 0.9005 - val_loss: 0.5124 - val_accuracy: 0.8718\n",
      "Epoch 41/600\n",
      "13661/13661 [==============================] - 5s 384us/sample - loss: 0.2989 - accuracy: 0.9008 - val_loss: 0.5173 - val_accuracy: 0.8697\n",
      "Epoch 42/600\n",
      "13661/13661 [==============================] - 5s 390us/sample - loss: 0.2978 - accuracy: 0.9013 - val_loss: 0.5183 - val_accuracy: 0.8732\n",
      "Epoch 00042: early stopping\n",
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 6s 431us/sample - loss: 0.6486 - accuracy: 0.6502 - val_loss: 0.6552 - val_accuracy: 0.6522\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 5s 355us/sample - loss: 0.6472 - accuracy: 0.6522 - val_loss: 0.6554 - val_accuracy: 0.6522\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 5s 352us/sample - loss: 0.6471 - accuracy: 0.6523 - val_loss: 0.6551 - val_accuracy: 0.6522\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 5s 343us/sample - loss: 0.6475 - accuracy: 0.6521 - val_loss: 0.6546 - val_accuracy: 0.6522\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 5s 343us/sample - loss: 0.6475 - accuracy: 0.6522 - val_loss: 0.6513 - val_accuracy: 0.6522\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.6472 - accuracy: 0.6522 - val_loss: 0.6507 - val_accuracy: 0.6522\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.6473 - accuracy: 0.6522 - val_loss: 0.6496 - val_accuracy: 0.6522\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.6457 - accuracy: 0.6522 - val_loss: 0.6546 - val_accuracy: 0.6522\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.6447 - accuracy: 0.6522 - val_loss: 0.6506 - val_accuracy: 0.6522\n",
      "Epoch 10/600\n",
      "13661/13661 [==============================] - 5s 344us/sample - loss: 0.6438 - accuracy: 0.6522 - val_loss: 0.6520 - val_accuracy: 0.6522\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 5s 347us/sample - loss: 0.6409 - accuracy: 0.6522 - val_loss: 0.6529 - val_accuracy: 0.6522\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 5s 345us/sample - loss: 0.6350 - accuracy: 0.6522 - val_loss: 0.6561 - val_accuracy: 0.6522\n",
      "Epoch 13/600\n",
      "13661/13661 [==============================] - 5s 350us/sample - loss: 0.6298 - accuracy: 0.6523 - val_loss: 0.6633 - val_accuracy: 0.6522\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 5s 345us/sample - loss: 0.6265 - accuracy: 0.6522 - val_loss: 0.6653 - val_accuracy: 0.6522\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 5s 346us/sample - loss: 0.6197 - accuracy: 0.6522 - val_loss: 0.6757 - val_accuracy: 0.6522\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 5s 367us/sample - loss: 0.6155 - accuracy: 0.6522 - val_loss: 0.6940 - val_accuracy: 0.6522\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 4s 326us/sample - loss: 0.6130 - accuracy: 0.6521 - val_loss: 0.6882 - val_accuracy: 0.6522\n",
      "Epoch 18/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.6090 - accuracy: 0.6518 - val_loss: 0.6948 - val_accuracy: 0.6522\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.6079 - accuracy: 0.6513 - val_loss: 0.7071 - val_accuracy: 0.6522\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.6044 - accuracy: 0.6541 - val_loss: 0.7057 - val_accuracy: 0.6511\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.6005 - accuracy: 0.6546 - val_loss: 0.7266 - val_accuracy: 0.6429\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 5s 348us/sample - loss: 0.5948 - accuracy: 0.6666 - val_loss: 0.7385 - val_accuracy: 0.6376\n",
      "Epoch 23/600\n",
      "13661/13661 [==============================] - 5s 344us/sample - loss: 0.5895 - accuracy: 0.6717 - val_loss: 0.7461 - val_accuracy: 0.6355\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 5s 347us/sample - loss: 0.5825 - accuracy: 0.6795 - val_loss: 0.7789 - val_accuracy: 0.6358\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.5779 - accuracy: 0.6847 - val_loss: 0.7782 - val_accuracy: 0.6338\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.5722 - accuracy: 0.6911 - val_loss: 0.7946 - val_accuracy: 0.62766 - \n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.5658 - accuracy: 0.6939 - val_loss: 0.8294 - val_accuracy: 0.6294- accu\n",
      "Epoch 28/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.5627 - accuracy: 0.6951 - val_loss: 0.8114 - val_accuracy: 0.6306\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 337us/sample - loss: 0.5601 - accuracy: 0.6988 - val_loss: 0.8439 - val_accuracy: 0.6294\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.5552 - accuracy: 0.7006 - val_loss: 0.8906 - val_accuracy: 0.6314\n",
      "Epoch 31/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.5556 - accuracy: 0.6997 - val_loss: 0.8998 - val_accuracy: 0.6285\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.5519 - accuracy: 0.7022 - val_loss: 0.9300 - val_accuracy: 0.6262\n",
      "Epoch 00032: early stopping\n",
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 5s 398us/sample - loss: 0.5644 - accuracy: 0.7509 - val_loss: 0.6069 - val_accuracy: 0.7544\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.5590 - accuracy: 0.7545 - val_loss: 0.5929 - val_accuracy: 0.7544\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 5s 335us/sample - loss: 0.5590 - accuracy: 0.7545 - val_loss: 0.5988 - val_accuracy: 0.7544\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.5594 - accuracy: 0.7545 - val_loss: 0.5937 - val_accuracy: 0.7544\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 4s 328us/sample - loss: 0.5590 - accuracy: 0.7545 - val_loss: 0.5911 - val_accuracy: 0.7544\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.5591 - accuracy: 0.7545 - val_loss: 0.5891 - val_accuracy: 0.7544\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 5s 338us/sample - loss: 0.5581 - accuracy: 0.7545 - val_loss: 0.5980 - val_accuracy: 0.7544\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 5s 333us/sample - loss: 0.5588 - accuracy: 0.7545 - val_loss: 0.5818 - val_accuracy: 0.7544\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 5s 333us/sample - loss: 0.5582 - accuracy: 0.7545 - val_loss: 0.5809 - val_accuracy: 0.7544\n",
      "Epoch 10/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.5582 - accuracy: 0.7545 - val_loss: 0.5809 - val_accuracy: 0.7544\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.5578 - accuracy: 0.7545 - val_loss: 0.5756 - val_accuracy: 0.7544\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.5571 - accuracy: 0.7545 - val_loss: 0.5862 - val_accuracy: 0.7544\n",
      "Epoch 13/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.5571 - accuracy: 0.7545 - val_loss: 0.5732 - val_accuracy: 0.7544\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 5s 367us/sample - loss: 0.5561 - accuracy: 0.7545 - val_loss: 0.5790 - val_accuracy: 0.7544\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 5s 346us/sample - loss: 0.5525 - accuracy: 0.7545 - val_loss: 0.5726 - val_accuracy: 0.7544\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.5516 - accuracy: 0.7545 - val_loss: 0.5776 - val_accuracy: 0.7544\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.5485 - accuracy: 0.7544 - val_loss: 0.5768 - val_accuracy: 0.7544\n",
      "Epoch 18/600\n",
      "13661/13661 [==============================] - 5s 343us/sample - loss: 0.5461 - accuracy: 0.7543 - val_loss: 0.5800 - val_accuracy: 0.7544\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.5420 - accuracy: 0.7543 - val_loss: 0.5834 - val_accuracy: 0.7544\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.5373 - accuracy: 0.7540 - val_loss: 0.5834 - val_accuracy: 0.7544\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 5s 333us/sample - loss: 0.5332 - accuracy: 0.7561 - val_loss: 0.5903 - val_accuracy: 0.7494\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 5s 340us/sample - loss: 0.5267 - accuracy: 0.7581 - val_loss: 0.6015 - val_accuracy: 0.7453\n",
      "Epoch 23/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.5174 - accuracy: 0.7645 - val_loss: 0.6118 - val_accuracy: 0.7418\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 5s 347us/sample - loss: 0.5108 - accuracy: 0.7699 - val_loss: 0.6307 - val_accuracy: 0.7389\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 5s 347us/sample - loss: 0.5059 - accuracy: 0.7726 - val_loss: 0.6472 - val_accuracy: 0.7406\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.4977 - accuracy: 0.7770 - val_loss: 0.6399 - val_accuracy: 0.7418\n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 5s 340us/sample - loss: 0.4917 - accuracy: 0.7796 - val_loss: 0.6623 - val_accuracy: 0.7424\n",
      "Epoch 28/600\n",
      "13661/13661 [==============================] - 4s 318us/sample - loss: 0.4903 - accuracy: 0.7795 - val_loss: 0.6686 - val_accuracy: 0.7447\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 360us/sample - loss: 0.4866 - accuracy: 0.7811 - val_loss: 0.6878 - val_accuracy: 0.7433\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 4s 316us/sample - loss: 0.4856 - accuracy: 0.7810 - val_loss: 0.6722 - val_accuracy: 0.7444\n",
      "Epoch 31/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.4808 - accuracy: 0.7842 - val_loss: 0.6998 - val_accuracy: 0.7424\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 5s 354us/sample - loss: 0.4791 - accuracy: 0.7854 - val_loss: 0.7146 - val_accuracy: 0.7441\n",
      "Epoch 33/600\n",
      "13661/13661 [==============================] - 5s 341us/sample - loss: 0.4771 - accuracy: 0.7857 - val_loss: 0.7141 - val_accuracy: 0.7459\n",
      "Epoch 34/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.4764 - accuracy: 0.7851 - val_loss: 0.7174 - val_accuracy: 0.7468\n",
      "Epoch 35/600\n",
      "13661/13661 [==============================] - 5s 332us/sample - loss: 0.4758 - accuracy: 0.7866 - val_loss: 0.7143 - val_accuracy: 0.7433\n",
      "Epoch 36/600\n",
      "13661/13661 [==============================] - 5s 342us/sample - loss: 0.4746 - accuracy: 0.7868 - val_loss: 0.7078 - val_accuracy: 0.7418\n",
      "Epoch 37/600\n",
      "13661/13661 [==============================] - 5s 348us/sample - loss: 0.4725 - accuracy: 0.7887 - val_loss: 0.7411 - val_accuracy: 0.7427\n",
      "Epoch 38/600\n",
      "13661/13661 [==============================] - 4s 322us/sample - loss: 0.4711 - accuracy: 0.7881 - val_loss: 0.7425 - val_accuracy: 0.7415\n",
      "Epoch 39/600\n",
      "13661/13661 [==============================] - 4s 322us/sample - loss: 0.4696 - accuracy: 0.7890 - val_loss: 0.7558 - val_accuracy: 0.7441\n",
      "Epoch 40/600\n",
      "13661/13661 [==============================] - 4s 320us/sample - loss: 0.4698 - accuracy: 0.7887 - val_loss: 0.7904 - val_accuracy: 0.7430\n",
      "Epoch 00040: early stopping\n",
      "Train on 13661 samples, validate on 3416 samples\n",
      "Epoch 1/600\n",
      "13661/13661 [==============================] - 5s 370us/sample - loss: 0.3157 - accuracy: 0.9097 - val_loss: 0.4063 - val_accuracy: 0.9095\n",
      "Epoch 2/600\n",
      "13661/13661 [==============================] - 5s 330us/sample - loss: 0.3071 - accuracy: 0.9097 - val_loss: 0.4100 - val_accuracy: 0.9095\n",
      "Epoch 3/600\n",
      "13661/13661 [==============================] - 5s 331us/sample - loss: 0.3062 - accuracy: 0.9097 - val_loss: 0.4048 - val_accuracy: 0.9095\n",
      "Epoch 4/600\n",
      "13661/13661 [==============================] - 5s 329us/sample - loss: 0.3066 - accuracy: 0.9097 - val_loss: 0.4106 - val_accuracy: 0.9095\n",
      "Epoch 5/600\n",
      "13661/13661 [==============================] - 4s 324us/sample - loss: 0.3055 - accuracy: 0.9097 - val_loss: 0.3929 - val_accuracy: 0.9095\n",
      "Epoch 6/600\n",
      "13661/13661 [==============================] - 4s 321us/sample - loss: 0.3050 - accuracy: 0.9097 - val_loss: 0.4068 - val_accuracy: 0.9095\n",
      "Epoch 7/600\n",
      "13661/13661 [==============================] - 4s 326us/sample - loss: 0.3043 - accuracy: 0.9097 - val_loss: 0.3903 - val_accuracy: 0.9095\n",
      "Epoch 8/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.3037 - accuracy: 0.9097 - val_loss: 0.3936 - val_accuracy: 0.9095\n",
      "Epoch 9/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.3033 - accuracy: 0.9097 - val_loss: 0.3869 - val_accuracy: 0.9095\n",
      "Epoch 10/600\n",
      "13661/13661 [==============================] - 4s 327us/sample - loss: 0.3024 - accuracy: 0.9097 - val_loss: 0.3961 - val_accuracy: 0.9095\n",
      "Epoch 11/600\n",
      "13661/13661 [==============================] - 4s 323us/sample - loss: 0.3015 - accuracy: 0.9097 - val_loss: 0.3909 - val_accuracy: 0.9095\n",
      "Epoch 12/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.3003 - accuracy: 0.9097 - val_loss: 0.3669 - val_accuracy: 0.9095\n",
      "Epoch 13/600\n",
      "13661/13661 [==============================] - 4s 320us/sample - loss: 0.2988 - accuracy: 0.9097 - val_loss: 0.3678 - val_accuracy: 0.9095\n",
      "Epoch 14/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.2979 - accuracy: 0.9097 - val_loss: 0.3805 - val_accuracy: 0.9095\n",
      "Epoch 15/600\n",
      "13661/13661 [==============================] - 4s 322us/sample - loss: 0.2963 - accuracy: 0.9097 - val_loss: 0.3825 - val_accuracy: 0.9095\n",
      "Epoch 16/600\n",
      "13661/13661 [==============================] - 4s 329us/sample - loss: 0.2930 - accuracy: 0.9097 - val_loss: 0.3787 - val_accuracy: 0.9095\n",
      "Epoch 17/600\n",
      "13661/13661 [==============================] - 4s 323us/sample - loss: 0.2925 - accuracy: 0.9097 - val_loss: 0.3840 - val_accuracy: 0.9095\n",
      "Epoch 18/600\n",
      "13661/13661 [==============================] - 5s 351us/sample - loss: 0.2926 - accuracy: 0.9097 - val_loss: 0.3774 - val_accuracy: 0.9095\n",
      "Epoch 19/600\n",
      "13661/13661 [==============================] - 5s 347us/sample - loss: 0.2908 - accuracy: 0.9097 - val_loss: 0.3877 - val_accuracy: 0.9095\n",
      "Epoch 20/600\n",
      "13661/13661 [==============================] - 5s 361us/sample - loss: 0.2883 - accuracy: 0.9097 - val_loss: 0.3868 - val_accuracy: 0.9095\n",
      "Epoch 21/600\n",
      "13661/13661 [==============================] - 5s 375us/sample - loss: 0.2888 - accuracy: 0.9097 - val_loss: 0.3894 - val_accuracy: 0.9095\n",
      "Epoch 22/600\n",
      "13661/13661 [==============================] - 5s 376us/sample - loss: 0.2868 - accuracy: 0.9097 - val_loss: 0.3933 - val_accuracy: 0.9095\n",
      "Epoch 23/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13661/13661 [==============================] - 5s 356us/sample - loss: 0.2858 - accuracy: 0.9097 - val_loss: 0.4167 - val_accuracy: 0.9095\n",
      "Epoch 24/600\n",
      "13661/13661 [==============================] - 5s 370us/sample - loss: 0.2860 - accuracy: 0.9097 - val_loss: 0.4233 - val_accuracy: 0.9095\n",
      "Epoch 25/600\n",
      "13661/13661 [==============================] - 5s 348us/sample - loss: 0.2847 - accuracy: 0.9097 - val_loss: 0.4118 - val_accuracy: 0.9095\n",
      "Epoch 26/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.2841 - accuracy: 0.9097 - val_loss: 0.4252 - val_accuracy: 0.9095\n",
      "Epoch 27/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.2830 - accuracy: 0.9097 - val_loss: 0.4249 - val_accuracy: 0.9095\n",
      "Epoch 28/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.2813 - accuracy: 0.9097 - val_loss: 0.4307 - val_accuracy: 0.9098\n",
      "Epoch 29/600\n",
      "13661/13661 [==============================] - 5s 334us/sample - loss: 0.2783 - accuracy: 0.9100 - val_loss: 0.4415 - val_accuracy: 0.9098\n",
      "Epoch 30/600\n",
      "13661/13661 [==============================] - 5s 353us/sample - loss: 0.2748 - accuracy: 0.9099 - val_loss: 0.4290 - val_accuracy: 0.9046\n",
      "Epoch 31/600\n",
      "13661/13661 [==============================] - 5s 338us/sample - loss: 0.2714 - accuracy: 0.9124 - val_loss: 0.4506 - val_accuracy: 0.9011\n",
      "Epoch 32/600\n",
      "13661/13661 [==============================] - 5s 337us/sample - loss: 0.2712 - accuracy: 0.9128 - val_loss: 0.4459 - val_accuracy: 0.9022\n",
      "Epoch 33/600\n",
      "13661/13661 [==============================] - 5s 338us/sample - loss: 0.2663 - accuracy: 0.9148 - val_loss: 0.4790 - val_accuracy: 0.8972\n",
      "Epoch 34/600\n",
      "13661/13661 [==============================] - 5s 344us/sample - loss: 0.2638 - accuracy: 0.9152 - val_loss: 0.4754 - val_accuracy: 0.9008\n",
      "Epoch 35/600\n",
      "13661/13661 [==============================] - 5s 338us/sample - loss: 0.2630 - accuracy: 0.9181 - val_loss: 0.5119 - val_accuracy: 0.9025\n",
      "Epoch 36/600\n",
      "13661/13661 [==============================] - 5s 336us/sample - loss: 0.2579 - accuracy: 0.9193 - val_loss: 0.5125 - val_accuracy: 0.9019\n",
      "Epoch 37/600\n",
      "13661/13661 [==============================] - 5s 339us/sample - loss: 0.2576 - accuracy: 0.9187 - val_loss: 0.5231 - val_accuracy: 0.9037\n",
      "Epoch 00037: early stopping\n",
      "Train on 13651 samples, validate on 3413 samples\n",
      "Epoch 1/600\n",
      "13651/13651 [==============================] - 5s 391us/sample - loss: 0.1991 - accuracy: 0.9536 - val_loss: 0.3400 - val_accuracy: 0.9537\n",
      "Epoch 2/600\n",
      "13651/13651 [==============================] - 5s 347us/sample - loss: 0.1916 - accuracy: 0.9536 - val_loss: 0.2939 - val_accuracy: 0.9537\n",
      "Epoch 3/600\n",
      "13651/13651 [==============================] - 5s 343us/sample - loss: 0.1904 - accuracy: 0.9536 - val_loss: 0.2900 - val_accuracy: 0.9537\n",
      "Epoch 4/600\n",
      "13651/13651 [==============================] - 5s 345us/sample - loss: 0.1912 - accuracy: 0.9536 - val_loss: 0.3427 - val_accuracy: 0.9537\n",
      "Epoch 5/600\n",
      "13651/13651 [==============================] - 5s 357us/sample - loss: 0.1899 - accuracy: 0.9536 - val_loss: 0.3630 - val_accuracy: 0.9537\n",
      "Epoch 6/600\n",
      "13651/13651 [==============================] - 5s 341us/sample - loss: 0.1901 - accuracy: 0.9536 - val_loss: 0.3343 - val_accuracy: 0.9537\n",
      "Epoch 7/600\n",
      "13651/13651 [==============================] - 5s 351us/sample - loss: 0.1891 - accuracy: 0.9536 - val_loss: 0.3432 - val_accuracy: 0.9537\n",
      "Epoch 8/600\n",
      "13651/13651 [==============================] - 5s 342us/sample - loss: 0.1887 - accuracy: 0.9536 - val_loss: 0.3375 - val_accuracy: 0.9537\n",
      "Epoch 9/600\n",
      "13651/13651 [==============================] - 4s 316us/sample - loss: 0.1884 - accuracy: 0.9536 - val_loss: 0.2769 - val_accuracy: 0.9537\n",
      "Epoch 10/600\n",
      "13651/13651 [==============================] - 5s 336us/sample - loss: 0.1880 - accuracy: 0.9536 - val_loss: 0.2949 - val_accuracy: 0.9537\n",
      "Epoch 11/600\n",
      "13651/13651 [==============================] - 5s 346us/sample - loss: 0.1876 - accuracy: 0.9536 - val_loss: 0.2949 - val_accuracy: 0.9537\n",
      "Epoch 12/600\n",
      "13651/13651 [==============================] - 5s 340us/sample - loss: 0.1860 - accuracy: 0.9536 - val_loss: 0.2992 - val_accuracy: 0.9537\n",
      "Epoch 13/600\n",
      "13651/13651 [==============================] - 4s 321us/sample - loss: 0.1861 - accuracy: 0.9536 - val_loss: 0.3049 - val_accuracy: 0.9537\n",
      "Epoch 14/600\n",
      "13651/13651 [==============================] - 5s 340us/sample - loss: 0.1832 - accuracy: 0.9536 - val_loss: 0.3129 - val_accuracy: 0.9537\n",
      "Epoch 15/600\n",
      "13651/13651 [==============================] - 5s 391us/sample - loss: 0.1807 - accuracy: 0.9536 - val_loss: 0.3324 - val_accuracy: 0.9537\n",
      "Epoch 16/600\n",
      "13651/13651 [==============================] - 5s 356us/sample - loss: 0.1799 - accuracy: 0.9536 - val_loss: 0.3228 - val_accuracy: 0.9537\n",
      "Epoch 17/600\n",
      "13651/13651 [==============================] - 5s 360us/sample - loss: 0.1798 - accuracy: 0.9536 - val_loss: 0.2895 - val_accuracy: 0.9537\n",
      "Epoch 18/600\n",
      "13651/13651 [==============================] - 5s 333us/sample - loss: 0.1782 - accuracy: 0.9536 - val_loss: 0.3127 - val_accuracy: 0.9537\n",
      "Epoch 19/600\n",
      "13651/13651 [==============================] - 4s 324us/sample - loss: 0.1776 - accuracy: 0.9536 - val_loss: 0.3161 - val_accuracy: 0.9537\n",
      "Epoch 20/600\n",
      "13651/13651 [==============================] - 5s 330us/sample - loss: 0.1761 - accuracy: 0.9536 - val_loss: 0.3205 - val_accuracy: 0.9537\n",
      "Epoch 21/600\n",
      "13651/13651 [==============================] - 5s 347us/sample - loss: 0.1737 - accuracy: 0.9534 - val_loss: 0.3082 - val_accuracy: 0.9528\n",
      "Epoch 22/600\n",
      "13651/13651 [==============================] - 4s 327us/sample - loss: 0.1726 - accuracy: 0.9537 - val_loss: 0.3138 - val_accuracy: 0.9531\n",
      "Epoch 23/600\n",
      "13651/13651 [==============================] - 4s 329us/sample - loss: 0.1698 - accuracy: 0.9545 - val_loss: 0.2982 - val_accuracy: 0.9514\n",
      "Epoch 24/600\n",
      "13651/13651 [==============================] - 4s 325us/sample - loss: 0.1669 - accuracy: 0.9544 - val_loss: 0.3236 - val_accuracy: 0.9476\n",
      "Epoch 25/600\n",
      "13651/13651 [==============================] - 5s 335us/sample - loss: 0.1641 - accuracy: 0.9555 - val_loss: 0.3122 - val_accuracy: 0.9458\n",
      "Epoch 26/600\n",
      "13651/13651 [==============================] - 5s 338us/sample - loss: 0.1623 - accuracy: 0.9563 - val_loss: 0.3189 - val_accuracy: 0.9420\n",
      "Epoch 27/600\n",
      "13651/13651 [==============================] - 5s 342us/sample - loss: 0.1609 - accuracy: 0.9565 - val_loss: 0.3294 - val_accuracy: 0.9455\n",
      "Epoch 28/600\n",
      "13651/13651 [==============================] - 5s 339us/sample - loss: 0.1579 - accuracy: 0.9580 - val_loss: 0.3233 - val_accuracy: 0.9437\n",
      "Epoch 29/600\n",
      "13651/13651 [==============================] - 5s 339us/sample - loss: 0.1589 - accuracy: 0.9574 - val_loss: 0.3246 - val_accuracy: 0.9420\n",
      "Epoch 30/600\n",
      "13651/13651 [==============================] - 5s 361us/sample - loss: 0.1567 - accuracy: 0.9589 - val_loss: 0.3233 - val_accuracy: 0.9455\n",
      "Epoch 31/600\n",
      "13651/13651 [==============================] - 5s 369us/sample - loss: 0.1568 - accuracy: 0.9583 - val_loss: 0.3398 - val_accuracy: 0.9455\n",
      "Epoch 32/600\n",
      "13651/13651 [==============================] - 5s 349us/sample - loss: 0.1555 - accuracy: 0.9588 - val_loss: 0.3441 - val_accuracy: 0.9440\n",
      "Epoch 33/600\n",
      "13651/13651 [==============================] - 5s 341us/sample - loss: 0.1549 - accuracy: 0.9591 - val_loss: 0.3368 - val_accuracy: 0.9467\n",
      "Epoch 34/600\n",
      "13651/13651 [==============================] - 5s 345us/sample - loss: 0.1547 - accuracy: 0.9590 - val_loss: 0.3474 - val_accuracy: 0.9414\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "for topic in topic_cols:\n",
    "    topics_text_vectors = topics[['goal_domain_mean_pos', topic]]\n",
    "    topics_text_vectors.dropna(inplace=True)\n",
    "    text = topics_text_vectors['goal_domain_mean_pos']\n",
    "    y = topics_text_vectors[topic]\n",
    "    token = Tokenizer()\n",
    "    token.fit_on_texts(text)\n",
    "    vocab_size = len(token.word_index) + 1\n",
    "    encoded_text = token.texts_to_sequences(text)\n",
    "    max_len = int()\n",
    "    for i in encoded_text:\n",
    "        len_ = len(i)\n",
    "        if len_ > max_len:\n",
    "            max_len = len_\n",
    "    X = pad_sequences(encoded_text, maxlen=max_len, padding='post')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "    model = create_model()\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test= np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "    model.fit(X_train, y_train, epochs=600, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "    name = topic.split('_')[-1]\n",
    "    model.save(f\"../models/topics_domain/domain_{name}_vect_nn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
