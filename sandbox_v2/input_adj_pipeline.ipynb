{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = {\n",
    "    'goal_name':'обновление устаревшей информации',\n",
    "    'goal_result':'Да, четко',\n",
    "    'goal_type':'Развить имеющиеся знания и навыки',\n",
    "    'goal_first_step':'поиск необходимой информации',\n",
    "    'goal_domain':'Прикладные знания и навыки, ручной труд',\n",
    "    'goal_obstacle':'Не вижу преград',\n",
    "    'goal_time':'Нет жестких сроков',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.DataFrame.from_dict(dummy_input, orient='index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def you_know_first_steps(x):\n",
    "    if x:\n",
    "        if 'не знаю' in x.lower():\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['are_first_steps_known'] = input_df.loc[:, 'goal_first_step'].apply(lambda x: you_know_first_steps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_related = ['лет', 'год ', 'меся', 'недел', 'дне', 'года']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_time_certain(x):\n",
    "    if x:\n",
    "        x = str(x).lower()\n",
    "        for i in time_related:\n",
    "            if i in x:\n",
    "                return 1\n",
    "            else:\n",
    "                continue\n",
    "        return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['is_time_certain'] = input_df['goal_time'].apply(lambda x: is_time_certain(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def certainly_imagined(x):\n",
    "    if x:\n",
    "        if ' четко' in x.lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['is_certainly_imagined'] = input_df['goal_result'].apply(lambda x: certainly_imagined(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_obstackles_expected(x):\n",
    "    if x:\n",
    "        if 'не вижу преград' in str(x).lower() or 'нет' in str(x).lower():\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['are_obstackles_expected'] = input_df['goal_obstacle'].apply(lambda x: are_obstackles_expected(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.drop(columns=['goal_result', 'goal_first_step', 'goal_obstacle', 'goal_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['space'] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['name_type'] = input_df['goal_name'] + input_df['space'] + input_df['goal_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.drop(columns=['goal_name', 'goal_type', 'space'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain'] = input_df['goal_domain'].apply(lambda x: str(x).lower())\n",
    "input_df['name_type'] = input_df['name_type'].apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "specials_to_remove = [\n",
    "    '.', '\"', \"'\", '?', '(', ')', '`',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special(x):\n",
    "    for special in specials_to_remove:\n",
    "        if special in x:\n",
    "            x =  x.replace(special, '').strip()\n",
    "        else:\n",
    "            pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain'] = input_df['goal_domain'].apply(lambda x: remove_special(x))\n",
    "input_df['name_type'] = input_df['name_type'].apply(lambda x: remove_special(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "specials_to_replace = [\n",
    "    '-', '\\\\', '/', ','\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_special(x):\n",
    "    for special in specials_to_replace:\n",
    "        if special in x:\n",
    "            x =  x.replace(special, ' ').strip()\n",
    "        else:\n",
    "            pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain'] = input_df['goal_domain'].apply(lambda x: replace_special(x))\n",
    "input_df['name_type'] = input_df['name_type'].apply(lambda x: replace_special(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_of_words(x):\n",
    "    return x.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain_LoW'] = input_df['goal_domain'].apply(lambda x: create_list_of_words(x))\n",
    "input_df['name_type_LoW'] = input_df['name_type'].apply(lambda x: create_list_of_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pos = ['NOUN', 'VERB', 'NUMR', 'ADJF', 'ADJS', 'INFN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_LoW_nv(x):\n",
    "    clean_LoW_nv = []\n",
    "    for word in x:\n",
    "        if word.isdigit() == True:\n",
    "            clean_LoW_nv.append(word)\n",
    "        else:\n",
    "            p = morph.parse(word)[0]\n",
    "            normal_form = p.normal_form\n",
    "            pos = p.tag\n",
    "            stop = 0\n",
    "            for s_pos in key_pos:\n",
    "                if s_pos in pos:\n",
    "                    clean_LoW_nv.append(normal_form)\n",
    "                else:\n",
    "                    continue\n",
    "    return ' '.join(clean_LoW_nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain_clean_NV_LoW'] = input_df['goal_domain_LoW'].apply(lambda x: clean_LoW_nv(x))\n",
    "input_df['name_type_clean_NV_LoW'] = input_df['name_type_LoW'].apply(lambda x: clean_LoW_nv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['topic_words'] = input_df['goal_domain_LoW'].apply(lambda x: word_counter(x))\n",
    "input_df['goal_words'] = input_df['name_type_LoW'].apply(lambda x: word_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_counter(x):\n",
    "    counter = int()\n",
    "    for word in x:\n",
    "        counter += len(word)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['topic_letters'] = input_df['goal_domain_LoW'].apply(lambda x: letters_counter(x))\n",
    "input_df['goal_letters'] = input_df['name_type_LoW'].apply(lambda x: letters_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['topic_aver_word_len'] = round(input_df['topic_letters'].div(input_df['topic_words']), 2)\n",
    "input_df['goal_aver_word_len'] = round(input_df['goal_letters'].div(input_df['goal_words']), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_counter(x, pos_to_comp):\n",
    "    pos_counter = int()\n",
    "    for word in x:\n",
    "        p = morph.parse(word)[0]\n",
    "        pos = p.tag\n",
    "        for pos_ in pos_to_comp:\n",
    "            if pos_ in pos:\n",
    "                pos_counter += 1\n",
    "            else:\n",
    "                pass\n",
    "    return pos_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_verbs_counter'] = input_df['name_type_LoW'].apply(lambda x: pos_counter(x, ['VERB', 'INFN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_nouns_counter'] = input_df['name_type_LoW'].apply(lambda x: pos_counter(x, ['NOUN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_numr_counter'] = input_df['name_type_LoW'].apply(lambda x: pos_counter(x, ['NUMR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_adj_counter'] = input_df['name_type_LoW'].apply(lambda x: pos_counter(x, ['ADJF', 'ADJS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_counter(x):\n",
    "    digit_counter = int()\n",
    "    for word in x:\n",
    "        if word.isdigit() == True:\n",
    "            digit_counter += 1\n",
    "    return digit_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_digit_counter'] = input_df['name_type_LoW'].apply(lambda x: digit_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goal_domain', 'are_first_steps_known', 'is_time_certain',\n",
       "       'is_certainly_imagined', 'are_obstackles_expected', 'name_type',\n",
       "       'goal_domain_LoW', 'name_type_LoW', 'goal_domain_clean_NV_LoW',\n",
       "       'name_type_clean_NV_LoW', 'topic_words', 'goal_words', 'topic_letters',\n",
       "       'goal_letters', 'topic_aver_word_len', 'goal_aver_word_len',\n",
       "       'goal_verbs_counter', 'goal_nouns_counter', 'goal_numr_counter',\n",
       "       'goal_adj_counter', 'goal_digit_counter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = input_df[['are_first_steps_known', 'is_time_certain',\n",
    "               'is_certainly_imagined', 'are_obstackles_expected',\n",
    "                'topic_words', 'goal_words', 'topic_letters',\n",
    "               'goal_letters', 'topic_aver_word_len', 'goal_aver_word_len',\n",
    "               'goal_verbs_counter', 'goal_nouns_counter', 'goal_numr_counter',\n",
    "               'goal_adj_counter', 'goal_digit_counter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "features = mms.fit_transform(df_features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = input_df[['name_type_clean_NV_LoW']] # only name-type for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_vectors['name_type_clean_NV_LoW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/tfidf.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = tfidf.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4932)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = input_df[['name_type_clean_NV_LoW']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_vectors['name_type_clean_NV_LoW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = token.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 142\n",
    "X = pad_sequences(encoded_text, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_tool_vect_nn = load_model('models/topic_tool_vect_nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(topic_tool_vect_nn.predict(X), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/topic_tool_vect_xgb.pkl', 'rb') as f:\n",
    "    tool_vect_xgb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_vect_xgb.predict(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/specific_feat_xgb.pkl', 'rb') as f:\n",
    "    specific_feat_xgb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_feat_xgb.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/topics_tesaurus.pickle', 'rb') as f:\n",
    "    topics_tesaurus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_attractor_knowledge': ['знан',\n",
       "  'зако',\n",
       "  'прав',\n",
       "  'нау',\n",
       "  'образов',\n",
       "  'биолог',\n",
       "  'философ',\n",
       "  'социолог',\n",
       "  'изуч',\n",
       "  'литерат',\n",
       "  'язык',\n",
       "  'учеб',\n",
       "  'экономика',\n",
       "  'экология',\n",
       "  'кулинар',\n",
       "  'энергети',\n",
       "  'электро',\n",
       "  'обуч',\n",
       "  'безопасн',\n",
       "  'хими',\n",
       "  'стоматол',\n",
       "  'педиат',\n",
       "  'вет',\n",
       "  'логопед',\n",
       "  'строител',\n",
       "  'ремонт',\n",
       "  'культур',\n",
       "  'учёб',\n",
       "  'гомеопат'],\n",
       " 'label_attractor_hard_skill': ['математи',\n",
       "  'программирова',\n",
       "  'ии',\n",
       "  'ит',\n",
       "  'it',\n",
       "  'дизайн',\n",
       "  'графи',\n",
       "  'создан',\n",
       "  'юрис',\n",
       "  'медицин',\n",
       "  'психо',\n",
       "  'педагоги',\n",
       "  'предпринимател',\n",
       "  'воспита',\n",
       "  'разработ',\n",
       "  'по',\n",
       "  'прикладн',\n",
       "  'инженер',\n",
       "  'hard',\n",
       "  'информац',\n",
       "  'иннов',\n",
       "  'ритор',\n",
       "  'автомех',\n",
       "  'флори',\n",
       "  'фарма',\n",
       "  'косметол',\n",
       "  'логист',\n",
       "  'цифр',\n",
       "  'машин',\n",
       "  'металл',\n",
       "  'механ',\n",
       "  'гео',\n",
       "  'экос',\n",
       "  'агро',\n",
       "  'меха',\n",
       "  'дефект',\n",
       "  'свар',\n",
       "  'хлебопеч',\n",
       "  'шахмат',\n",
       "  'освоен'],\n",
       " 'label_attractor_soft_skill': ['soft',\n",
       "  'саморазвит',\n",
       "  'дисциплин',\n",
       "  'общен',\n",
       "  'дипломат',\n",
       "  'коммуни',\n",
       "  'soft',\n",
       "  'commun',\n",
       "  'врем',\n",
       "  'мышл'],\n",
       " 'label_attractor_tool': ['техн',\n",
       "  '1с',\n",
       "  'cdo',\n",
       "  'edtech',\n",
       "  'corporate finullce',\n",
       "  'нти',\n",
       "  'оборудован'],\n",
       " 'label_attractor_community': ['обществ',\n",
       "  'семья',\n",
       "  'семьей',\n",
       "  'люд',\n",
       "  'семью',\n",
       "  'семейн',\n",
       "  'worldskill',\n",
       "  'wsr',\n",
       "  'социал',\n",
       "  'стран',\n",
       "  'домашн',\n",
       "  'волонт',\n",
       "  'отношен',\n",
       "  'ислам',\n",
       "  'религ',\n",
       "  'рсо',\n",
       "  'предложени',\n",
       "  'фестивал'],\n",
       " 'label_attractor_subjectivity': ['благ',\n",
       "  'личност',\n",
       "  'личн',\n",
       "  'мисси',\n",
       "  'эмоц',\n",
       "  'развле',\n",
       "  'собствен',\n",
       "  'независ',\n",
       "  'ден',\n",
       "  '💰',\n",
       "  'само',\n",
       "  'заработ',\n",
       "  'успех',\n",
       "  'себя',\n",
       "  'материаль'],\n",
       " 'label_attractor_habits': ['привыч'],\n",
       " 'label_attractor_career': ['карьер',\n",
       "  'работа',\n",
       "  'сфер',\n",
       "  'отрасл',\n",
       "  'бизнес',\n",
       "  'государст',\n",
       "  'финанс',\n",
       "  'жкх',\n",
       "  'управл',\n",
       "  'маркетинг',\n",
       "  'руковод',\n",
       "  'здравоохран',\n",
       "  'дело',\n",
       "  'проф',\n",
       "  'менедж',\n",
       "  'врач',\n",
       "  'деятел',\n",
       "  'производ',\n",
       "  'админ',\n",
       "  'парик',\n",
       "  'услуг',\n",
       "  'сервис',\n",
       "  'работ',\n",
       "  'журналис',\n",
       "  'организац',\n",
       "  'хозяйс',\n",
       "  'hr',\n",
       "  'консал',\n",
       "  'продвижен',\n",
       "  'нтр',\n",
       "  'труд',\n",
       "  'экспанс'],\n",
       " 'label_attractor_fixing': ['вуз', 'колледж', 'гму'],\n",
       " 'label_attractor_art': ['худож',\n",
       "  'искусств',\n",
       "  'фото',\n",
       "  'творч',\n",
       "  'мечт',\n",
       "  'жизн',\n",
       "  'духов',\n",
       "  'хобби',\n",
       "  'мир',\n",
       "  'просвещ',\n",
       "  'путешеств',\n",
       "  'эстет',\n",
       "  'решени'],\n",
       " 'label_attractor_health': ['здоров',\n",
       "  'спорт',\n",
       "  'зож',\n",
       "  'тури',\n",
       "  'питан',\n",
       "  'внешн',\n",
       "  'вес',\n",
       "  'полезн',\n",
       "  'крас'],\n",
       " 'label_attractor_undefined': ['нет',\n",
       "  'все',\n",
       "  'всё',\n",
       "  'не',\n",
       "  'секрет',\n",
       "  'ок',\n",
       "  '-',\n",
       "  '*',\n",
       "  '1',\n",
       "  'угодн',\n",
       "  'никак',\n",
       "  '.',\n",
       "  'любой',\n",
       "  'любая',\n",
       "  'чромомл',\n",
       "  'общее',\n",
       "  'тема']}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_tesaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
