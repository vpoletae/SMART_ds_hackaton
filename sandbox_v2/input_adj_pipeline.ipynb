{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = {\n",
    "    'goal_name':'–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É—Å—Ç–∞—Ä–µ–≤—à–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏',\n",
    "    'goal_result':'–î–∞, —á–µ—Ç–∫–æ',\n",
    "    'goal_type':'–†–∞–∑–≤–∏—Ç—å –∏–º–µ—é—â–∏–µ—Å—è –∑–Ω–∞–Ω–∏—è –∏ –Ω–∞–≤—ã–∫–∏',\n",
    "    'goal_first_step':'–ø–æ–∏—Å–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏',\n",
    "    'goal_domain':'–ü—Ä–∏–∫–ª–∞–¥–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ –Ω–∞–≤—ã–∫–∏, —Ä—É—á–Ω–æ–π —Ç—Ä—É–¥',\n",
    "    'goal_obstacle':'–ù–µ –≤–∏–∂—É –ø—Ä–µ–≥—Ä–∞–¥',\n",
    "    'goal_time':'–ù–µ—Ç –∂–µ—Å—Ç–∫–∏—Ö —Å—Ä–æ–∫–æ–≤',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.DataFrame.from_dict(dummy_input, orient='index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def you_know_first_steps(x):\n",
    "    if x:\n",
    "        if '–Ω–µ –∑–Ω–∞—é' in x.lower():\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['are_first_steps_known'] = input_df.loc[:, 'goal_first_step'].apply(lambda x: you_know_first_steps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_related = ['–ª–µ—Ç', '–≥–æ–¥ ', '–º–µ—Å—è', '–Ω–µ–¥–µ–ª', '–¥–Ω–µ', '–≥–æ–¥–∞']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_time_certain(x):\n",
    "    if x:\n",
    "        x = str(x).lower()\n",
    "        for i in time_related:\n",
    "            if i in x:\n",
    "                return 1\n",
    "            else:\n",
    "                continue\n",
    "        return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['is_time_certain'] = input_df['goal_time'].apply(lambda x: is_time_certain(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def certainly_imagined(x):\n",
    "    if x:\n",
    "        if ' —á–µ—Ç–∫–æ' in x.lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['is_certainly_imagined'] = input_df['goal_result'].apply(lambda x: certainly_imagined(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_obstackles_expected(x):\n",
    "    if x:\n",
    "        if '–Ω–µ –≤–∏–∂—É –ø—Ä–µ–≥—Ä–∞–¥' in str(x).lower() or '–Ω–µ—Ç' in str(x).lower():\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['are_obstackles_expected'] = input_df['goal_obstacle'].apply(lambda x: are_obstackles_expected(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.drop(columns=['goal_result', 'goal_first_step', 'goal_obstacle', 'goal_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['space'] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['name_type'] = input_df['goal_name'] + input_df['space'] + input_df['goal_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.drop(columns=['goal_name', 'goal_type', 'space'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain'] = input_df['goal_domain'].apply(lambda x: str(x).lower())\n",
    "input_df['name_type'] = input_df['name_type'].apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "specials_to_remove = [\n",
    "    '.', '\"', \"'\", '?', '(', ')', '`',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special(x):\n",
    "    for special in specials_to_remove:\n",
    "        if special in x:\n",
    "            x =  x.replace(special, '').strip()\n",
    "        else:\n",
    "            pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain'] = input_df['goal_domain'].apply(lambda x: remove_special(x))\n",
    "input_df['name_type'] = input_df['name_type'].apply(lambda x: remove_special(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "specials_to_replace = [\n",
    "    '-', '\\\\', '/', ','\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_special(x):\n",
    "    for special in specials_to_replace:\n",
    "        if special in x:\n",
    "            x =  x.replace(special, ' ').strip()\n",
    "        else:\n",
    "            pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain'] = input_df['goal_domain'].apply(lambda x: replace_special(x))\n",
    "input_df['name_type'] = input_df['name_type'].apply(lambda x: replace_special(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_of_words(x):\n",
    "    return x.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain_LoW'] = input_df['goal_domain'].apply(lambda x: create_list_of_words(x))\n",
    "input_df['name_type_LoW'] = input_df['name_type'].apply(lambda x: create_list_of_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pos = ['NOUN', 'VERB', 'NUMR', 'ADJF', 'ADJS', 'INFN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_LoW_nv(x):\n",
    "    clean_LoW_nv = []\n",
    "    for word in x:\n",
    "        if word.isdigit() == True:\n",
    "            clean_LoW_nv.append(word)\n",
    "        else:\n",
    "            p = morph.parse(word)[0]\n",
    "            normal_form = p.normal_form\n",
    "            pos = p.tag\n",
    "            stop = 0\n",
    "            for s_pos in key_pos:\n",
    "                if s_pos in pos:\n",
    "                    clean_LoW_nv.append(normal_form)\n",
    "                else:\n",
    "                    continue\n",
    "    return ' '.join(clean_LoW_nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_domain_clean_NV_LoW'] = input_df['goal_domain_LoW'].apply(lambda x: clean_LoW_nv(x))\n",
    "input_df['name_type_clean_NV_LoW'] = input_df['name_type_LoW'].apply(lambda x: clean_LoW_nv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['topic_words'] = input_df['goal_domain_LoW'].apply(lambda x: word_counter(x))\n",
    "input_df['goal_words'] = input_df['name_type_LoW'].apply(lambda x: word_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_counter(x):\n",
    "    counter = int()\n",
    "    for word in x:\n",
    "        counter += len(word)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['topic_letters'] = input_df['goal_domain_LoW'].apply(lambda x: letters_counter(x))\n",
    "input_df['goal_letters'] = input_df['name_type_LoW'].apply(lambda x: letters_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['topic_aver_word_len'] = round(input_df['topic_letters'].div(input_df['topic_words']), 2)\n",
    "input_df['goal_aver_word_len'] = round(input_df['goal_letters'].div(input_df['goal_words']), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_counter(x, pos_to_comp):\n",
    "    pos_counter = int()\n",
    "    for word in x:\n",
    "        p = morph.parse(word)[0]\n",
    "        pos = p.tag\n",
    "        for pos_ in pos_to_comp:\n",
    "            if pos_ in pos:\n",
    "                pos_counter += 1\n",
    "            else:\n",
    "                pass\n",
    "    return pos_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_verbs_counter'] = input_df['name_type_LoW'].apply(lambda x: pos_counter(x, ['VERB', 'INFN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_nouns_counter'] = input_df['name_type_LoW'].apply(lambda x: pos_counter(x, ['NOUN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_numr_counter'] = input_df['name_type_LoW'].apply(lambda x: pos_counter(x, ['NUMR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_adj_counter'] = input_df['name_type_LoW'].apply(lambda x: pos_counter(x, ['ADJF', 'ADJS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_counter(x):\n",
    "    digit_counter = int()\n",
    "    for word in x:\n",
    "        if word.isdigit() == True:\n",
    "            digit_counter += 1\n",
    "    return digit_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['goal_digit_counter'] = input_df['name_type_LoW'].apply(lambda x: digit_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goal_domain', 'are_first_steps_known', 'is_time_certain',\n",
       "       'is_certainly_imagined', 'are_obstackles_expected', 'name_type',\n",
       "       'goal_domain_LoW', 'name_type_LoW', 'goal_domain_clean_NV_LoW',\n",
       "       'name_type_clean_NV_LoW', 'topic_words', 'goal_words', 'topic_letters',\n",
       "       'goal_letters', 'topic_aver_word_len', 'goal_aver_word_len',\n",
       "       'goal_verbs_counter', 'goal_nouns_counter', 'goal_numr_counter',\n",
       "       'goal_adj_counter', 'goal_digit_counter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = input_df[['are_first_steps_known', 'is_time_certain',\n",
    "               'is_certainly_imagined', 'are_obstackles_expected',\n",
    "                'topic_words', 'goal_words', 'topic_letters',\n",
    "               'goal_letters', 'topic_aver_word_len', 'goal_aver_word_len',\n",
    "               'goal_verbs_counter', 'goal_nouns_counter', 'goal_numr_counter',\n",
    "               'goal_adj_counter', 'goal_digit_counter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "features = mms.fit_transform(df_features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = input_df[['name_type_clean_NV_LoW']] # only name-type for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_vectors['name_type_clean_NV_LoW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/tfidf.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = tfidf.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4932)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = input_df[['name_type_clean_NV_LoW']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_vectors['name_type_clean_NV_LoW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = token.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 142\n",
    "X = pad_sequences(encoded_text, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_tool_vect_nn = load_model('models/topic_tool_vect_nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(topic_tool_vect_nn.predict(X), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/topic_tool_vect_xgb.pkl', 'rb') as f:\n",
    "    tool_vect_xgb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_vect_xgb.predict(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/specific_feat_xgb.pkl', 'rb') as f:\n",
    "    specific_feat_xgb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_feat_xgb.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/topics_tesaurus.pickle', 'rb') as f:\n",
    "    topics_tesaurus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_attractor_knowledge': ['–∑–Ω–∞–Ω',\n",
       "  '–∑–∞–∫–æ',\n",
       "  '–ø—Ä–∞–≤',\n",
       "  '–Ω–∞—É',\n",
       "  '–æ–±—Ä–∞–∑–æ–≤',\n",
       "  '–±–∏–æ–ª–æ–≥',\n",
       "  '—Ñ–∏–ª–æ—Å–æ—Ñ',\n",
       "  '—Å–æ—Ü–∏–æ–ª–æ–≥',\n",
       "  '–∏–∑—É—á',\n",
       "  '–ª–∏—Ç–µ—Ä–∞—Ç',\n",
       "  '—è–∑—ã–∫',\n",
       "  '—É—á–µ–±',\n",
       "  '—ç–∫–æ–Ω–æ–º–∏–∫–∞',\n",
       "  '—ç–∫–æ–ª–æ–≥–∏—è',\n",
       "  '–∫—É–ª–∏–Ω–∞—Ä',\n",
       "  '—ç–Ω–µ—Ä–≥–µ—Ç–∏',\n",
       "  '—ç–ª–µ–∫—Ç—Ä–æ',\n",
       "  '–æ–±—É—á',\n",
       "  '–±–µ–∑–æ–ø–∞—Å–Ω',\n",
       "  '—Ö–∏–º–∏',\n",
       "  '—Å—Ç–æ–º–∞—Ç–æ–ª',\n",
       "  '–ø–µ–¥–∏–∞—Ç',\n",
       "  '–≤–µ—Ç',\n",
       "  '–ª–æ–≥–æ–ø–µ–¥',\n",
       "  '—Å—Ç—Ä–æ–∏—Ç–µ–ª',\n",
       "  '—Ä–µ–º–æ–Ω—Ç',\n",
       "  '–∫—É–ª—å—Ç—É—Ä',\n",
       "  '—É—á—ë–±',\n",
       "  '–≥–æ–º–µ–æ–ø–∞—Ç'],\n",
       " 'label_attractor_hard_skill': ['–º–∞—Ç–µ–º–∞—Ç–∏',\n",
       "  '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞',\n",
       "  '–∏–∏',\n",
       "  '–∏—Ç',\n",
       "  'it',\n",
       "  '–¥–∏–∑–∞–π–Ω',\n",
       "  '–≥—Ä–∞—Ñ–∏',\n",
       "  '—Å–æ–∑–¥–∞–Ω',\n",
       "  '—é—Ä–∏—Å',\n",
       "  '–º–µ–¥–∏—Ü–∏–Ω',\n",
       "  '–ø—Å–∏—Ö–æ',\n",
       "  '–ø–µ–¥–∞–≥–æ–≥–∏',\n",
       "  '–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª',\n",
       "  '–≤–æ—Å–ø–∏—Ç–∞',\n",
       "  '—Ä–∞–∑—Ä–∞–±–æ—Ç',\n",
       "  '–ø–æ',\n",
       "  '–ø—Ä–∏–∫–ª–∞–¥–Ω',\n",
       "  '–∏–Ω–∂–µ–Ω–µ—Ä',\n",
       "  'hard',\n",
       "  '–∏–Ω—Ñ–æ—Ä–º–∞—Ü',\n",
       "  '–∏–Ω–Ω–æ–≤',\n",
       "  '—Ä–∏—Ç–æ—Ä',\n",
       "  '–∞–≤—Ç–æ–º–µ—Ö',\n",
       "  '—Ñ–ª–æ—Ä–∏',\n",
       "  '—Ñ–∞—Ä–º–∞',\n",
       "  '–∫–æ—Å–º–µ—Ç–æ–ª',\n",
       "  '–ª–æ–≥–∏—Å—Ç',\n",
       "  '—Ü–∏—Ñ—Ä',\n",
       "  '–º–∞—à–∏–Ω',\n",
       "  '–º–µ—Ç–∞–ª–ª',\n",
       "  '–º–µ—Ö–∞–Ω',\n",
       "  '–≥–µ–æ',\n",
       "  '—ç–∫–æ—Å',\n",
       "  '–∞–≥—Ä–æ',\n",
       "  '–º–µ—Ö–∞',\n",
       "  '–¥–µ—Ñ–µ–∫—Ç',\n",
       "  '—Å–≤–∞—Ä',\n",
       "  '—Ö–ª–µ–±–æ–ø–µ—á',\n",
       "  '—à–∞—Ö–º–∞—Ç',\n",
       "  '–æ—Å–≤–æ–µ–Ω'],\n",
       " 'label_attractor_soft_skill': ['soft',\n",
       "  '—Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç',\n",
       "  '–¥–∏—Å—Ü–∏–ø–ª–∏–Ω',\n",
       "  '–æ–±—â–µ–Ω',\n",
       "  '–¥–∏–ø–ª–æ–º–∞—Ç',\n",
       "  '–∫–æ–º–º—É–Ω–∏',\n",
       "  'soft',\n",
       "  'commun',\n",
       "  '–≤—Ä–µ–º',\n",
       "  '–º—ã—à–ª'],\n",
       " 'label_attractor_tool': ['—Ç–µ—Ö–Ω',\n",
       "  '1—Å',\n",
       "  'cdo',\n",
       "  'edtech',\n",
       "  'corporate finullce',\n",
       "  '–Ω—Ç–∏',\n",
       "  '–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω'],\n",
       " 'label_attractor_community': ['–æ–±—â–µ—Å—Ç–≤',\n",
       "  '—Å–µ–º—å—è',\n",
       "  '—Å–µ–º—å–µ–π',\n",
       "  '–ª—é–¥',\n",
       "  '—Å–µ–º—å—é',\n",
       "  '—Å–µ–º–µ–π–Ω',\n",
       "  'worldskill',\n",
       "  'wsr',\n",
       "  '—Å–æ—Ü–∏–∞–ª',\n",
       "  '—Å—Ç—Ä–∞–Ω',\n",
       "  '–¥–æ–º–∞—à–Ω',\n",
       "  '–≤–æ–ª–æ–Ω—Ç',\n",
       "  '–æ—Ç–Ω–æ—à–µ–Ω',\n",
       "  '–∏—Å–ª–∞–º',\n",
       "  '—Ä–µ–ª–∏–≥',\n",
       "  '—Ä—Å–æ',\n",
       "  '–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏',\n",
       "  '—Ñ–µ—Å—Ç–∏–≤–∞–ª'],\n",
       " 'label_attractor_subjectivity': ['–±–ª–∞–≥',\n",
       "  '–ª–∏—á–Ω–æ—Å—Ç',\n",
       "  '–ª–∏—á–Ω',\n",
       "  '–º–∏—Å—Å–∏',\n",
       "  '—ç–º–æ—Ü',\n",
       "  '—Ä–∞–∑–≤–ª–µ',\n",
       "  '—Å–æ–±—Å—Ç–≤–µ–Ω',\n",
       "  '–Ω–µ–∑–∞–≤–∏—Å',\n",
       "  '–¥–µ–Ω',\n",
       "  'üí∞',\n",
       "  '—Å–∞–º–æ',\n",
       "  '–∑–∞—Ä–∞–±–æ—Ç',\n",
       "  '—É—Å–ø–µ—Ö',\n",
       "  '—Å–µ–±—è',\n",
       "  '–º–∞—Ç–µ—Ä–∏–∞–ª—å'],\n",
       " 'label_attractor_habits': ['–ø—Ä–∏–≤—ã—á'],\n",
       " 'label_attractor_career': ['–∫–∞—Ä—å–µ—Ä',\n",
       "  '—Ä–∞–±–æ—Ç–∞',\n",
       "  '—Å—Ñ–µ—Ä',\n",
       "  '–æ—Ç—Ä–∞—Å–ª',\n",
       "  '–±–∏–∑–Ω–µ—Å',\n",
       "  '–≥–æ—Å—É–¥–∞—Ä—Å—Ç',\n",
       "  '—Ñ–∏–Ω–∞–Ω—Å',\n",
       "  '–∂–∫—Ö',\n",
       "  '—É–ø—Ä–∞–≤–ª',\n",
       "  '–º–∞—Ä–∫–µ—Ç–∏–Ω–≥',\n",
       "  '—Ä—É–∫–æ–≤–æ–¥',\n",
       "  '–∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω',\n",
       "  '–¥–µ–ª–æ',\n",
       "  '–ø—Ä–æ—Ñ',\n",
       "  '–º–µ–Ω–µ–¥–∂',\n",
       "  '–≤—Ä–∞—á',\n",
       "  '–¥–µ—è—Ç–µ–ª',\n",
       "  '–ø—Ä–æ–∏–∑–≤–æ–¥',\n",
       "  '–∞–¥–º–∏–Ω',\n",
       "  '–ø–∞—Ä–∏–∫',\n",
       "  '—É—Å–ª—É–≥',\n",
       "  '—Å–µ—Ä–≤–∏—Å',\n",
       "  '—Ä–∞–±–æ—Ç',\n",
       "  '–∂—É—Ä–Ω–∞–ª–∏—Å',\n",
       "  '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü',\n",
       "  '—Ö–æ–∑—è–π—Å',\n",
       "  'hr',\n",
       "  '–∫–æ–Ω—Å–∞–ª',\n",
       "  '–ø—Ä–æ–¥–≤–∏–∂–µ–Ω',\n",
       "  '–Ω—Ç—Ä',\n",
       "  '—Ç—Ä—É–¥',\n",
       "  '—ç–∫—Å–ø–∞–Ω—Å'],\n",
       " 'label_attractor_fixing': ['–≤—É–∑', '–∫–æ–ª–ª–µ–¥–∂', '–≥–º—É'],\n",
       " 'label_attractor_art': ['—Ö—É–¥–æ–∂',\n",
       "  '–∏—Å–∫—É—Å—Å—Ç–≤',\n",
       "  '—Ñ–æ—Ç–æ',\n",
       "  '—Ç–≤–æ—Ä—á',\n",
       "  '–º–µ—á—Ç',\n",
       "  '–∂–∏–∑–Ω',\n",
       "  '–¥—É—Ö–æ–≤',\n",
       "  '—Ö–æ–±–±–∏',\n",
       "  '–º–∏—Ä',\n",
       "  '–ø—Ä–æ—Å–≤–µ—â',\n",
       "  '–ø—É—Ç–µ—à–µ—Å—Ç–≤',\n",
       "  '—ç—Å—Ç–µ—Ç',\n",
       "  '—Ä–µ—à–µ–Ω–∏'],\n",
       " 'label_attractor_health': ['–∑–¥–æ—Ä–æ–≤',\n",
       "  '—Å–ø–æ—Ä—Ç',\n",
       "  '–∑–æ–∂',\n",
       "  '—Ç—É—Ä–∏',\n",
       "  '–ø–∏—Ç–∞–Ω',\n",
       "  '–≤–Ω–µ—à–Ω',\n",
       "  '–≤–µ—Å',\n",
       "  '–ø–æ–ª–µ–∑–Ω',\n",
       "  '–∫—Ä–∞—Å'],\n",
       " 'label_attractor_undefined': ['–Ω–µ—Ç',\n",
       "  '–≤—Å–µ',\n",
       "  '–≤—Å—ë',\n",
       "  '–Ω–µ',\n",
       "  '—Å–µ–∫—Ä–µ—Ç',\n",
       "  '–æ–∫',\n",
       "  '-',\n",
       "  '*',\n",
       "  '1',\n",
       "  '—É–≥–æ–¥–Ω',\n",
       "  '–Ω–∏–∫–∞–∫',\n",
       "  '.',\n",
       "  '–ª—é–±–æ–π',\n",
       "  '–ª—é–±–∞—è',\n",
       "  '—á—Ä–æ–º–æ–º–ª',\n",
       "  '–æ–±—â–µ–µ',\n",
       "  '—Ç–µ–º–∞']}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_tesaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
